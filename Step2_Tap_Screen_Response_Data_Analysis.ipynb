{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook UI to generate TAP data for MWT_Dashboards!\n",
    "\n",
    "### Beginner Essentials:\n",
    "1. Shift-Enter to run each cell. After you run, you should see an output \"done step #\". If not, an error has occured\n",
    "2. When inputting your own code/revising the code, make sure you close all your quotation marks '' and brackets (), [], {}.\n",
    "3. Don't leave any commas (,) hanging! (make sure an object always follows a comma. If there is nothing after a comma, remove the comma!\n",
    "4. Learning to code? Each line of code is annotated to help you understand how this code works!\n",
    "\n",
    "**Run all cells/steps sequentially, even the ones that do not need input**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Analysis of the Jupyter Notebook\n",
    "\n",
    "| Step | Purpose | Key Actions |\n",
    "|------|---------|-------------|\n",
    "| **1. Import Packages** | Load required Python libraries for data analysis | Imports `pandas`, `numpy`, `matplotlib`, etc. | \n",
    "| **2. Pick Filepath** | User input: select folder containing `.trv` files | Uses `FileChooser` widget to select directory | \n",
    "| **3. User-Defined Variables** | Set experiment parameters | Defines: `number_of_taps`, `ISI`,`first_tap`; Calculates `tolerances` (time windows for taps) | \n",
    "| **4. Construct Filelist** | Find all `.trv` files in selected folder | Sets working directory and scans `folder_path` using; Displays no. of `.trv` files found in the folder |\n",
    "| **5. Process Data Function** | Define functions to load and clean `.trv` data to use in step 6| - `ProcessData()`: Loads files, calculates metrics (reversal probability, speed)<br>- `assign_taps()`: Labels data with tap numbers <br>- `insert_plates()` |\n",
    "| **6.1 Process Data (Input)** | Verify strain identifiers from file paths | Checks `filelist` for unique strain names (e.g., \"N2\") | `StrainNames` dictionary (maps strains to IDs) |\n",
    "| **6.2 Process Data (Run)** | Apply processing to all strains | Runs `ProcessData()` and `assign_taps()` for each strain | `DataLists` with cleaned DataFrames per strain |\n",
    "| **7. Grouping & Naming** | Combine data from all strains | - Concatenates DataFrames<br>- Assigns dataset names (e.g., \"N2\") | `TotalConcatenated` DataFrame with all processed data |\n",
    "| **Output CSV** | Save processed data | Exports `TotalConcatenated` to CSV (e.g., `PD_Screen_tap_output.csv`) | CSV file saved in working directory |\n",
    "\n",
    "### Key Notes:\n",
    "- User Input Required: Steps 2 (file selection), 3 (parameters), 6.1 (strain verification)\n",
    "- Output: Final CSV contains all analyzed tap response data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages Required (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #<- package used to import and organize data\n",
    "import numpy as np #<- package used to import and organize data\n",
    "import math\n",
    "import os #<- package used to work with system file paths\n",
    "import seaborn as sns #<- package used to plot graphs\n",
    "from matplotlib import pyplot as plt #<- another package used to plot graphs\n",
    "from itertools import cycle #<- package used to iterate down rows (used in step 5 to add tap column)\n",
    "import ipywidgets as widgets #<- widget tool to generate button and tab for graphs\n",
    "from IPython.display import display #<- displays widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "# from tkinter import Tk, filedialog #<- Tkinter is a GUI package\n",
    "print(\"done step 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pick filepath (just run and click button from output)\n",
    "\n",
    "Run the following cell and click the button 'Select Folder' to pick a filepath.\n",
    "\n",
    "**Important: Later on, this script uses the total file path for each file to import and group data. That means if your folder has whatever your strain is named, the script will not work.**\n",
    "\n",
    "(ex. if your folder has \"N2\" in it this script sees all files inside this folder as having the \"N2\" search key)\n",
    "\n",
    "**An easy fix is to just rename your folder to something else (make your strains lower-case, or just have the date)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a658ad74954429cac3410a4a699dc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Volumes', filename='', title='', show_hidden=False, select_desc='Select', change_desc='Chan…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starting_directory = '/Volumes'\n",
    "chooser = FileChooser(starting_directory)\n",
    "display(chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2\n"
     ]
    }
   ],
   "source": [
    "print(chooser.selected_path)\n",
    "folder_path=chooser.selected_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fce4c6515e47a69670fefe26a1fddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Screen:', options=('PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "screens = ['PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'Neuron_Genes_Screen']\n",
    "\n",
    "screen_chooser = widgets.Select(options=screens, value=screens[0], description='Screen:')\n",
    "display(screen_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Screen=screen_chooser.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User-Defined Variables (Add input here)\n",
    "\n",
    "Here, we add some constants to help you blaze through this code.\n",
    "\n",
    "3.1: Number of taps is pretty self-explanatory. How many taps does your experiment have? put in that number + 1 (N+1)!\n",
    "\n",
    "\n",
    "3.2: Change your ISI number. This will be reflected in the name/title of the output figure.\n",
    "\n",
    "\n",
    "**Note:** if you have different ISIs in the same folder, then come back and change this when you are graphing for the second set of data with the other ISI (Generally data from same ISIs are graphed together). If changing ISI mid-analysis, you can just skip straight to step 8 after running this cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Input\n",
    "number_of_taps = 30 # Taps in your experiment (N)\n",
    "\n",
    "# 3.2 Input\n",
    "ISI = 10  # ISI in your experiment\n",
    "first_tap = 600 # when is your first tap? check your TRV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap 1, tolerance: (598, 602)\n",
      "Tap 2, tolerance: (658, 662)\n",
      "Tap 3, tolerance: (718, 722)\n",
      "Tap 4, tolerance: (778, 782)\n",
      "Tap 5, tolerance: (838, 842)\n",
      "Tap 6, tolerance: (898, 902)\n",
      "Tap 7, tolerance: (958, 962)\n",
      "Tap 8, tolerance: (1018, 1022)\n",
      "Tap 9, tolerance: (1078, 1082)\n",
      "Tap 10, tolerance: (1138, 1142)\n",
      "Tap 11, tolerance: (1198, 1202)\n",
      "Tap 12, tolerance: (1258, 1262)\n",
      "Tap 13, tolerance: (1318, 1322)\n",
      "Tap 14, tolerance: (1378, 1382)\n",
      "Tap 15, tolerance: (1438, 1442)\n",
      "Tap 16, tolerance: (1498, 1502)\n",
      "Tap 17, tolerance: (1558, 1562)\n",
      "Tap 18, tolerance: (1618, 1622)\n",
      "Tap 19, tolerance: (1678, 1682)\n",
      "Tap 20, tolerance: (1738, 1742)\n",
      "Tap 21, tolerance: (1798, 1802)\n",
      "Tap 22, tolerance: (1858, 1862)\n",
      "Tap 23, tolerance: (1918, 1922)\n",
      "Tap 24, tolerance: (1978, 1982)\n",
      "Tap 25, tolerance: (2038, 2042)\n",
      "Tap 26, tolerance: (2098, 2102)\n",
      "Tap 27, tolerance: (2158, 2162)\n",
      "Tap 28, tolerance: (2218, 2222)\n",
      "Tap 29, tolerance: (2278, 2282)\n",
      "Tap 30, tolerance: (2338, 2342)\n",
      "Tap 31, tolerance: (1188, 1191)\n",
      "done step 3\n"
     ]
    }
   ],
   "source": [
    "# Here, open up one of the trv files to determine the times for each of these taps. \n",
    "\n",
    "# Record number of taps (N+1), e.g., if number_of_taps = 30, taps = [1, 2, 3, ..., 31]\n",
    "taps = np.arange(1, number_of_taps+2).tolist()\n",
    "\n",
    "# Assign tolerance to each tap\n",
    "lower = np.arange(first_tap-2, first_tap-2+(number_of_taps*ISI), ISI) # (first tap, last tap+10s, ISI)\n",
    "upper = np.arange(first_tap+2, first_tap+2+(number_of_taps*ISI), ISI) # (first tap, last tap+10s, ISI)\n",
    "tolerances = [(int(l), int(u)) for l, u in zip(lower, upper)]\n",
    "tolerances.append((1188,1191)) # (N+1)th tap\n",
    "\n",
    "# Display taps with tolerances \n",
    "for i in taps:\n",
    "    print(f\"Tap {i}, tolerance: {tolerances[i-1]}\")\n",
    "\n",
    "print(\"done step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Constructing Filelist From Source File/Select File (Just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .trv files to process: 5\n",
      "done step 4\n"
     ]
    }
   ],
   "source": [
    "#folder_path = '/Users/Joseph/Desktop/AVR14_10sISI' #- manual folder path if Tkinter is acting up\n",
    "\n",
    "os.chdir(folder_path) #<- setting your working directory so that your images will be saved here\n",
    "\n",
    "filelist = list() #<- empty list\n",
    "for root, dirs, files in os.walk(folder_path): #<- this for loop goes through your folder \n",
    "    for name in files:\n",
    "        if name.endswith('.trv'): # filters files with .trv (file that contains your data)\n",
    "            filepath = os.path.join(root, name) #<- Notes down the file path of each data file\n",
    "            filelist.append(filepath) #<- saves it into the list\n",
    "\n",
    "if not filelist:\n",
    "    raise FileNotFoundError(\"No .trv files found in the selected folder!\")\n",
    "else:\n",
    "    print(f\"Number of .trv files to process: {len(filelist)}\")\n",
    "    # print(f\"Example of first and last file saved: {filelist[0]}, {filelist[-1]}\") \n",
    "\n",
    "print('done step 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process Data Function (Just Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 5\n"
     ]
    }
   ],
   "source": [
    "def ProcessData(strain): \n",
    "    \"\"\"\n",
    "    Filters and processes .trv files matching the given strain.\n",
    "\n",
    "    Parameters: \n",
    "        strain (str): keyword to match in the files\n",
    "\n",
    "    Returns:\n",
    "        dict: N (Plate number) and Dataframe with required columns (\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\", \"Date\",\"Plate_id\",\"Screen\")\n",
    "\n",
    "    \"\"\"\n",
    "    strain_filelist = [x for x in filelist if strain in x] #<- goes through the list and filters for keyword\n",
    "    Strain_N = len(strain_filelist) # Finds the number of plates per strain\n",
    "    if Strain_N == 0:\n",
    "        raise AssertionError ('{} is not a good identifier as number of plates = 0'.format(strain))\n",
    "    else:\n",
    "        pass\n",
    "        print(f'Strain\" {strain}')\n",
    "        print(f'Number of plate: {Strain_N}') \n",
    "\n",
    "        # visiting files in this strain\n",
    "        strain_filelist = [file for file in filelist if strain in file]\n",
    "        df_list=[]\n",
    "        for file in strain_filelist:\n",
    "            if file.split('/')[-1].startswith('._'):\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"File: {file}\")\n",
    "                df= pd.read_csv(file, sep=' ', header = None, encoding_errors='ignore')\n",
    "                df['Plate_id'] = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "                df['Date'] = file.split('/')[-2].split('_')[0]\n",
    "                df['Screen'] = file.split('/')[-4]\n",
    "                df_list.append(df)\n",
    "        DF_Total = pd.concat(df_list, ignore_index = True)\n",
    "\n",
    "    # for f in strain_filelist:\n",
    "    #     DF_Total = pd.concat(pd.read_csv(f, sep=' ', skiprows = 4, header = None))\n",
    "    #     DF_Total = pd.concat([pd.read_csv(f, sep=' ', header = None, encoding_errors='ignore') for f in strain_filelist],\n",
    "    #                   ignore_index=True) #<- imports your data files\n",
    "    #     DF_Total = DF_Total.dropna(axis = 1) #<- cleans your data\n",
    "        \n",
    "        # column names for trv files\n",
    "        DF_Total = DF_Total.rename( #<- more cleaning\n",
    "                    {0:'time',\n",
    "                    2:'rev_before',\n",
    "                    3:'no_rev',\n",
    "                    4:'stim_rev',\n",
    "                    7:'dist',\n",
    "                    8:'dist_std',\n",
    "                    9:'dist_stderr',\n",
    "                    11:'dist_0th',\n",
    "                    12:'dist_1st',\n",
    "                    13:'dist_2nd',\n",
    "                    14:'dist_3rd',\n",
    "                    15:'dist_100th',\n",
    "                    18:'dura',\n",
    "                    19:'dura_std',\n",
    "                    20:'dura_stderr',\n",
    "                    22:'dura_0th',\n",
    "                    23:'dura_1st',\n",
    "                    24:'dura_2nd',\n",
    "                    25:'dura_3rd',\n",
    "                    26:'dura_100th'}, axis=1)\n",
    "        \n",
    "        # check function here for NaN Columns\n",
    "        DF_Total['plate'] = 0\n",
    "\n",
    "        # Calculate reversal probability \n",
    "        DF_Total['prob'] = DF_Total['stim_rev']/ (DF_Total['no_rev'] + DF_Total['stim_rev']) \n",
    "\n",
    "        # Calculate speed\n",
    "        DF_Total['speed'] = DF_Total['dist']/DF_Total['dura']\n",
    "\n",
    "        DF_Total_rows = int(DF_Total.shape[0])\n",
    "        print(f'This strain/treatment has {DF_Total_rows} total taps') # Outputs as the second number. Check if you are missing taps!\n",
    "\n",
    "        DF_Final = DF_Total[[\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\", \"Date\",\"Plate_id\",\"Screen\"]].copy()\n",
    "\n",
    "    return{\n",
    "            'N': Strain_N,\n",
    "            'Confirm':DF_Total,\n",
    "            'Final': DF_Final}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign_taps(DF, tolerances):\n",
    "    \"\"\"\n",
    "    Assigns tap number to each row in the DataFrame based on time tolerances.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to modify\n",
    "        tolerances (list of tuples): Each tuple is (lower, upper) time range\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    DF['taps'] = np.nan\n",
    "    for taps, tolerance in enumerate(tolerances): #[(99, 101), (109,111), ...]\n",
    "        tap_lower,tap_upper = tolerance\n",
    "        TimesInTapRange = DF['time'].between(tap_lower,tap_upper, inclusive=\"both\")\n",
    "        DF.loc[TimesInTapRange,'taps'] = taps+1 #set the tap to i where times are between\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def insert_plates(df):   \n",
    "    \"\"\"\n",
    "    Inserts a plate column into a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): any dataframe\n",
    "    \n",
    "    Returns: \n",
    "        pd.DataFrame: dataframe with a plate column\n",
    "    \"\"\"\n",
    "    df['plate']=(df['taps'] ==1).cumsum()\n",
    "\n",
    "\n",
    "            \n",
    "print('done step 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Process Data (PLEASE READ, Add input here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the hardest part - From your naming convention, you need to pick a unique identifier for each group.\n",
    "\n",
    "This means that all of names of your files for that strain should have that in common but is not commone with across all other files! If you did a good job naming your files and following a good naming convention, this should be easy.\n",
    "\n",
    "## Be careful and really look hard in your naming structure. Note you want an unique identifier in the entire file path for the same group of files. An easy mistake is to have the strain name in the overall folder name, in this case if you use your strain name as a keyword it would include all files in that folder!\n",
    "\n",
    "For example, if all your N2 files have a certain pattern like \"N2_5x4\" in this following example:\n",
    "'/Users/Joseph/Desktop/AVR14_10sISI_TapHab_0710_2019/N2/20190710_141740/N2_5x4_f94h20c_100s30x10s10s_C0710ab.trv'\n",
    "\n",
    "Then you need to set that identifier for the strain keyword:\n",
    "'Strain_1' = 'N2_5x4'\n",
    "\n",
    "## Depending on how many strains you are running for comparison, you may need to add/delete some lines!\n",
    "\n",
    "## You are not naming your data groups here, we have a step for that later!\n",
    "## Here, you want to note down ALL the strains you have in the folder\n",
    "\n",
    "If you have just 2 strains, add hashtags (#) in front of the lines you do not need.\n",
    "If you need more strains, just add more lines, following the same format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genotypes in the experiment: 1\n",
      "1: N2\n"
     ]
    }
   ],
   "source": [
    "genotype=[]\n",
    "for f in filelist:\n",
    "    genotype.append(f.split('/')[-3])\n",
    "\n",
    "genotypes=np.unique(genotype)\n",
    "\n",
    "StrainNames=dict(enumerate(genotypes,1))\n",
    "\n",
    "print(f\"Number of genotypes in the experiment: {len(genotypes)}\")\n",
    "\n",
    "# Display the first 5 Strain names in the experiment\n",
    "for k in list(StrainNames)[:5]:\n",
    "    print(f\"{k}: {StrainNames[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(StrainNames.values()))\n",
    "print(type(list(StrainNames.values())))\n",
    "print(type(list(StrainNames.values())[0]))\n",
    "print('done step 6.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Process Data (just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Volumes/JOSEPH/PD_Screen/F53B2.5_ok226/20220524_141642/ZE1_10x2_f72h20C_600s31x10s10s_B0520ba.trv') as f:\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLists = [0]  #<- generates empty list. 0 is there to account for python's index starting at 0. \n",
    "# we want indexing to start at 1 (when I say #1 I want the first point, not the second point)\n",
    "\n",
    "for s in list(StrainNames.values()): #<- goes through the dictionary in step 6.1 and processes data\n",
    "    if not s == '':\n",
    "#         threading.Thread(target=DataLists.append(ProcessData(s)['Final'])).start()\n",
    "        DataLists.append(ProcessData(s)['Final']) #<- appends all data into a list of dataframes\n",
    "\n",
    "\n",
    "for df in DataLists[1:]: \n",
    "    assign_taps(df, tolerances)\n",
    "for df in DataLists[1:]:    \n",
    "    insert_plates(df)\n",
    "       \n",
    "print('done step 6.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLists.append(ProcessData('vps-35_ok1880')['Final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataLists[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(genotypes))\n",
    "print(len(np.unique(genotypes)))\n",
    "print(len(DataLists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Grouping Data and Naming (Optional: Add input here)\n",
    "\n",
    "Here, you get to name your data groups/strain! Name your groups however you like under between the quotation marks for each strain.\n",
    "\n",
    "For example: If your Strain1 is N2 and you wish for the group to be called N2,\n",
    "your line should look like:\n",
    "\n",
    "DataLists[x].assign(dataset = 'N2')\n",
    "\n",
    "## Go back to step 6.1 to check which strain is which item on the DataLists.\n",
    "In this example, the first item on DataLists is N2.\n",
    "\n",
    "\n",
    "## Remember: Put your name in quotes. (ex: 'N2' and not N2)\n",
    "\n",
    "As default, the names are set to the unique identifier labels.\n",
    "\n",
    "## Depending on the number of strains you are running the comparison, you may have to delete/add lines of code (following the same format). \n",
    "## Remember to add/delete commas too.\n",
    "\n",
    "# If you want to change your groups, you do that here. \n",
    "For example, if you have 5 strains in your folder but only want to compare between 2 or 3 strains, designate that here and follow through with steps 6 and 7. Once you are done, come back to step 6 and change your groups again (You are going to have to change your graph titles for the second run-through though)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated=pd.DataFrame()\n",
    "for d in range(1,len(np.unique(genotypes))+1):\n",
    "    TotalConcatenated=pd.concat([TotalConcatenated,\n",
    "                                 DataLists[d].assign(dataset=StrainNames.get(d))])\n",
    "\n",
    "TotalConcatenated.reset_index(inplace=False)\n",
    "print(TotalConcatenated)\n",
    "\n",
    "#if TotalConcatenated[\"taps\"].loc[ind] is not 1:\n",
    "#   TotalConcatenated[\"taps\"].loc[ind:indices[c+1]] = list(range(1,len(TotalConcatenated[\"taps\"].loc[ind:indices[c+1]])+1))\n",
    "# missing_taps(TotalConcatenated, accurate_taps, tolerances)\n",
    "\n",
    "print('done step 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Colour Palette - Only run the below cell ONCE\n",
    "\n",
    "The following code sets the colour palette for the whole experiment - and then designate one colour to each strain. After this, if as you are graphing you take away some strains, you can do so with the colours still matching accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TotalConcatenated['dataset'].str.split(\"_\", n=1, expand=True))\n",
    "TotalConcatenated['Screen']=Screen\n",
    "print(TotalConcatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated[['Gene', 'Allele']] = TotalConcatenated['dataset'].str.split('_', n=1, expand=True)\n",
    "print(TotalConcatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated['Allele']=TotalConcatenated['Allele'].fillna('N2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated=TotalConcatenated.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated.to_csv(f'{TotalConcatenated.Screen[0].values[0]}_tap_output.csv')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A debugging cell to test for strain 'XJ1' (which is the old N2)\n",
    "print(TotalConcatenated[TotalConcatenated['Allele']=='XJ1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rankinlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
