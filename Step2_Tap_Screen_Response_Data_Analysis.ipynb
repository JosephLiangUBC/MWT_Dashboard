{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook UI to generate TAP data for MWT_Dashboards!\n",
    "\n",
    "### Beginner Essentials:\n",
    "1. Shift-Enter to run each cell. After you run, you should see an output \"done step #\". If not, an error has occured\n",
    "2. When inputting your own code/revising the code, make sure you close all your quotation marks '' and brackets (), [], {}.\n",
    "3. Don't leave any commas (,) hanging! (make sure an object always follows a comma. If there is nothing after a comma, remove the comma!\n",
    "4. Learning to code? Each line of code is annotated to help you understand how this code works!\n",
    "\n",
    "**Run all cells/steps sequentially, even the ones that do not need input**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Analysis of the Jupyter Notebook\n",
    "\n",
    "| Step | Purpose | Key Actions |\n",
    "|------|---------|-------------|\n",
    "| **1. Import Packages** | Load required Python libraries for data analysis | Imports `pandas`, `numpy`, `matplotlib`, etc. | \n",
    "| **2. Pick Filepath** | Select the folder containing experimental data files (.dat or .trv) | Input required: Uses `FileChooser` widget to select directory | \n",
    "| **3. User-Defined Variables** | Set experiment parameters | Defines: `number_of_taps`, `ISI`,`first_tap`; Calculates `tolerances` (time windows for taps) | \n",
    "| **4. Construct Filelist** | Find all `.trv` files in selected folder | Sets working directory and scans `folder_path` using; Displays no. of `.trv` files found in the folder |\n",
    "| **5. Process Data Function** | Define functions to load and clean `.trv` data to use in step 6| - `ProcessData()`: Loads files, calculates metrics (reversal probability, speed)<br>- `assign_taps()`: Labels data with tap numbers <br>- `insert_plates()` |\n",
    "| **6 Process Data** | Apply processing to all strains| - Checks `filelist` for unique strain names (e.g., \"N2\") <br>- Runs `ProcessData()` and `assign_taps()` for each strain | \n",
    "| **7. Grouping & Naming** | Combine data from all strains | - Concatenates DataFrames<br>- Assigns dataset names (e.g., \"N2\") | \n",
    "| **Output CSV** | Save processed data | Exports `TotalConcatenated` to CSV |\n",
    "\n",
    "### Key Notes:\n",
    "- User Input Required: Steps 2 (file selection), 3 (parameters)\n",
    "- Output: Final CSV contains all analyzed tap response data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages Required (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #<- package used to import and organize data\n",
    "import numpy as np #<- package used to import and organize data\n",
    "import math\n",
    "import os #<- package used to work with system file paths\n",
    "import seaborn as sns #<- package used to plot graphs\n",
    "from matplotlib import pyplot as plt #<- another package used to plot graphs\n",
    "from itertools import cycle #<- package used to iterate down rows (used in step 5 to add tap column)\n",
    "import ipywidgets as widgets #<- widget tool to generate button and tab for graphs\n",
    "from IPython.display import display #<- displays widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "# from tkinter import Tk, filedialog #<- Tkinter is a GUI package\n",
    "print(\"done step 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pick filepath (just run and click button from output)\n",
    "\n",
    "Run the following cell and click the button 'Select Folder' to pick a filepath.\n",
    "\n",
    "**Important: Later on, this script uses the total file path for each file to import and group data. That means if your folder has whatever your strain is named, the script will not work.**\n",
    "\n",
    "(ex. if your folder has \"N2\" in it this script sees all files inside this folder as having the \"N2\" search key)\n",
    "\n",
    "**An easy fix is to just rename your folder to something else (make your strains lower-case, or just have the date)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bedb12d9f9642dab278a247a0631441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users', filename='', title='', show_hidden=False, select_desc='Select', change_desc='Change…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starting_directory = '/Users'\n",
    "chooser = FileChooser(starting_directory)\n",
    "display(chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022\n"
     ]
    }
   ],
   "source": [
    "print(chooser.selected_path)\n",
    "folder_path=chooser.selected_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a84fd2036894711bc371f0a0065d9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Screen:', options=('PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "screens = ['PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'Neuron_Genes_Screen']\n",
    "\n",
    "screen_chooser = widgets.Select(options=screens, value=screens[0], description='Screen:')\n",
    "display(screen_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Screen=screen_chooser.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User-Defined Variables (Add input here)\n",
    "\n",
    "Here, we add some constants to help you blaze through this code.\n",
    "\n",
    "3.1: Number of taps is pretty self-explanatory. How many taps does your experiment have? put in that number + 1 (N+1)!\n",
    "\n",
    "\n",
    "3.2: Change your ISI number. This will be reflected in the name/title of the output figure.\n",
    "\n",
    "\n",
    "**Note:** if you have different ISIs in the same folder, then come back and change this when you are graphing for the second set of data with the other ISI (Generally data from same ISIs are graphed together). If changing ISI mid-analysis, you can just skip straight to step 8 after running this cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Input\n",
    "number_of_taps = 30 # Taps in your experiment (N)\n",
    "\n",
    "# 3.2 Input\n",
    "ISI = 10  # ISI in your experiment\n",
    "first_tap = 600 # when is your first tap? check your TRV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap 1, tolerance: (598, 602)\n",
      "Tap 2, tolerance: (608, 612)\n",
      "Tap 3, tolerance: (618, 622)\n",
      "Tap 4, tolerance: (628, 632)\n",
      "Tap 5, tolerance: (638, 642)\n",
      "Tap 6, tolerance: (648, 652)\n",
      "Tap 7, tolerance: (658, 662)\n",
      "Tap 8, tolerance: (668, 672)\n",
      "Tap 9, tolerance: (678, 682)\n",
      "Tap 10, tolerance: (688, 692)\n",
      "Tap 11, tolerance: (698, 702)\n",
      "Tap 12, tolerance: (708, 712)\n",
      "Tap 13, tolerance: (718, 722)\n",
      "Tap 14, tolerance: (728, 732)\n",
      "Tap 15, tolerance: (738, 742)\n",
      "Tap 16, tolerance: (748, 752)\n",
      "Tap 17, tolerance: (758, 762)\n",
      "Tap 18, tolerance: (768, 772)\n",
      "Tap 19, tolerance: (778, 782)\n",
      "Tap 20, tolerance: (788, 792)\n",
      "Tap 21, tolerance: (798, 802)\n",
      "Tap 22, tolerance: (808, 812)\n",
      "Tap 23, tolerance: (818, 822)\n",
      "Tap 24, tolerance: (828, 832)\n",
      "Tap 25, tolerance: (838, 842)\n",
      "Tap 26, tolerance: (848, 852)\n",
      "Tap 27, tolerance: (858, 862)\n",
      "Tap 28, tolerance: (868, 872)\n",
      "Tap 29, tolerance: (878, 882)\n",
      "Tap 30, tolerance: (888, 892)\n",
      "Tap 31, tolerance: (1188, 1191)\n",
      "done step 3\n"
     ]
    }
   ],
   "source": [
    "# Here, open up one of the trv files to determine the times for each of these taps. \n",
    "\n",
    "# Record number of taps (N+1), e.g., if number_of_taps = 30, taps = [1, 2, 3, ..., 31]\n",
    "taps = np.arange(1, number_of_taps+2).tolist()\n",
    "\n",
    "# Assign tolerance to each tap\n",
    "lower = np.arange(first_tap-2, first_tap-2+(number_of_taps*ISI), ISI) # (first tap, last tap+10s, ISI)\n",
    "upper = np.arange(first_tap+2, first_tap+2+(number_of_taps*ISI), ISI) # (first tap, last tap+10s, ISI)\n",
    "tolerances = [(int(l), int(u)) for l, u in zip(lower, upper)]\n",
    "tolerances.append((1188,1191)) # (N+1)th tap\n",
    "\n",
    "# Display taps with tolerances \n",
    "for i in taps:\n",
    "    print(f\"Tap {i}, tolerance: {tolerances[i-1]}\")\n",
    "\n",
    "print(\"done step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Constructing Filelist From Source File/Select File (Just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .trv files to process: 13\n",
      "done step 4\n"
     ]
    }
   ],
   "source": [
    "#folder_path = '/Users/Joseph/Desktop/AVR14_10sISI' #- manual folder path if Tkinter is acting up\n",
    "\n",
    "os.chdir(folder_path) #<- setting your working directory so that your images will be saved here\n",
    "\n",
    "filelist = list() #<- empty list\n",
    "for root, dirs, files in os.walk(folder_path): #<- this for loop goes through your folder \n",
    "    for name in files:\n",
    "        if name.endswith('.trv'): # filters files with .trv (file that contains your data)\n",
    "            filepath = os.path.join(root, name) #<- Notes down the file path of each data file\n",
    "            filelist.append(filepath) #<- saves it into the list\n",
    "\n",
    "if not filelist:\n",
    "    raise FileNotFoundError(\"No .trv files found in the selected folder!\")\n",
    "else:\n",
    "    print(f\"Number of .trv files to process: {len(filelist)}\")\n",
    "    # print(f\"Example of first and last file saved: {filelist[0]}, {filelist[-1]}\") \n",
    "\n",
    "print('done step 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process Data Function (Just Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 5\n"
     ]
    }
   ],
   "source": [
    "def ProcessData(strain): \n",
    "    \"\"\"\n",
    "    Filters and processes .trv files matching the given strain.\n",
    "\n",
    "    Parameters: \n",
    "        strain (str): keyword to match in the files\n",
    "\n",
    "    Returns:\n",
    "        dict: N (Plate number) and Dataframe with required columns (\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\", \"Date\",\"Plate_id\",\"Screen\")\n",
    "\n",
    "    \"\"\"\n",
    "    strain_filelist = [x for x in filelist if strain in x] #<- Goes through the list and filters for keyword\n",
    "    Strain_N = len(strain_filelist) # Finds the number of plates per strain\n",
    "    if Strain_N == 0:\n",
    "        raise AssertionError ('{} is not a good identifier as number of plates = 0'.format(strain))\n",
    "    else:\n",
    "        pass\n",
    "        print(f'Strain {strain}')\n",
    "        print(f'Number of plates: {Strain_N}') \n",
    "\n",
    "        # visiting files in this strain\n",
    "        strain_filelist = [file for file in filelist if strain in file]\n",
    "        df_list=[]\n",
    "        for file in strain_filelist:\n",
    "            if file.split('/')[-1].startswith('._'):\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"File: {file}\")\n",
    "                df= pd.read_csv(file, sep=' ', header = None, encoding_errors='ignore')\n",
    "                df['Plate_id'] = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "                df['Date'] = file.split('/')[-2].split('_')[0]\n",
    "                df['Screen'] = file.split('/')[-4]\n",
    "                df_list.append(df)\n",
    "        DF_Total = pd.concat(df_list, ignore_index = True)\n",
    "        DF_Total = DF_Total.rename( #<- more cleaning\n",
    "                    {0:'time',\n",
    "                    2:'rev_before',\n",
    "                    3:'no_rev',\n",
    "                    4:'stim_rev',\n",
    "                    7:'dist',\n",
    "                    8:'dist_std',\n",
    "                    9:'dist_stderr',\n",
    "                    11:'dist_0th',\n",
    "                    12:'dist_1st',\n",
    "                    13:'dist_2nd',\n",
    "                    14:'dist_3rd',\n",
    "                    15:'dist_100th',\n",
    "                    18:'dura',\n",
    "                    19:'dura_std',\n",
    "                    20:'dura_stderr',\n",
    "                    22:'dura_0th',\n",
    "                    23:'dura_1st',\n",
    "                    24:'dura_2nd',\n",
    "                    25:'dura_3rd',\n",
    "                    26:'dura_100th'}, axis=1)\n",
    "        \n",
    "        # check function here for NaN Columns\n",
    "        DF_Total['plate'] = 0\n",
    "\n",
    "        # Calculate reversal probability \n",
    "        DF_Total['prob'] = DF_Total['stim_rev']/ (DF_Total['no_rev'] + DF_Total['stim_rev']) \n",
    "\n",
    "        # Calculate speed\n",
    "        DF_Total['speed'] = DF_Total['dist']/DF_Total['dura']\n",
    "\n",
    "        DF_Total_rows = int(DF_Total.shape[0])\n",
    "        print(f'This strain/treatment has {DF_Total_rows} total taps') # Outputs as the second number. Check if you are missing taps!\n",
    "\n",
    "        DF_Final = DF_Total[[\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\", \"Date\",\"Plate_id\",\"Screen\"]].copy()\n",
    "\n",
    "        print(\"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    return{\n",
    "            'N': Strain_N,\n",
    "            'Confirm':DF_Total,\n",
    "            'Final': DF_Final}\n",
    "\n",
    "\n",
    "\n",
    "def assign_taps(df, tolerances):\n",
    "    \"\"\"\n",
    "    Assigns tap number to each row in the DataFrame based on time tolerances.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to modify\n",
    "        tolerances (list of tuples): Each tuple is (lower, upper) time range\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df['taps'] = np.nan\n",
    "    for taps, tolerance in enumerate(tolerances): #[(99, 101), (109,111), ...]\n",
    "        tap_lower,tap_upper = tolerance\n",
    "        TimesInTapRange = df['time'].between(tap_lower,tap_upper, inclusive=\"both\")\n",
    "        df.loc[TimesInTapRange,'taps'] = taps+1 # set the tap to i where times are between\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def insert_plates(df):   \n",
    "    \"\"\"\n",
    "    Inserts a plate column into a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): any dataframe\n",
    "    \n",
    "    Returns: \n",
    "        pd.DataFrame: dataframe with a plate column\n",
    "    \"\"\"\n",
    "    df['plate']=(df['taps'] ==1).cumsum()\n",
    "\n",
    "\n",
    "            \n",
    "print('done step 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Process Data\n",
    "\n",
    "Gurmehak - New Annotation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genotypes/strains in the experiment: 3\n",
      "1: N2\n",
      "2: hipr-1_ok1081\n",
      "3: hipr-1_tm10120\n"
     ]
    }
   ],
   "source": [
    "genotype=[]\n",
    "for f in filelist:\n",
    "    genotype.append(f.split('/')[-3])\n",
    "\n",
    "genotypes=np.unique(genotype)\n",
    "\n",
    "StrainNames=dict(enumerate(genotypes,1))\n",
    "\n",
    "print(f\"Number of genotypes/strains in the experiment: {len(genotypes)}\")\n",
    "\n",
    "# Display the first 5 Strain names in the experiment\n",
    "for k in list(StrainNames)[:5]:\n",
    "    print(f\"{k}: {StrainNames[k]}\")\n",
    "\n",
    "print('done step 6.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Process Data (just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strain N2\n",
      "Number of plates: 5\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_101538/N2_10x2_f72h20C_600s31x10s10s_B0811ab.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_102652/N2_10x2_f96h20C_600s31x10s10s_A0811aa.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_122801/N2_10x2_f96h20C_600s31x10s10s_A0811ad.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_121502/N2_10x2_f72h20C_600s31x10s10s_B0811ae.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_103433/N2_10x2_f72h20C_600s31x10s10s_C0811ac.trv\n",
      "This strain/treatment has 155 total taps\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Strain hipr-1_ok1081\n",
      "Number of plates: 4\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_ok1081/20220815_114829_removed/RB1102_10x2_f96h20C_600s31x10s10s_A0811bc.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_ok1081/20220815_100526/RB1102_10x2_f72h20C_600s31x10s10s_C0811bb.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_ok1081/20220815_114931/RB1102_10x2_f72h20C_600s31x10s10s_B0811bd.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_ok1081/20220815_120440/RB1102_10x2_f72h20C_600s31x10s10s_C0811be.trv\n",
      "This strain/treatment has 123 total taps\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Strain hipr-1_tm10120\n",
      "Number of plates: 4\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_tm10120/20220815_111005/FX31344_10x2_f72h20C_600s31x10s10s_B0811cc.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_tm10120/20220815_113906_removed/FX31344_10x2_f72h20C_600s31x10s10s_C0811cd.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_tm10120/20220815_093805/FX31344_10x2_f72h20C_600s31x10s10s_C0811ca.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/hipr-1_tm10120/20220815_112320/FX31344_10x2_f96h20C_600s31x10s10s_A0811cb.trv\n",
      "This strain/treatment has 124 total taps\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "done step 6.2\n"
     ]
    }
   ],
   "source": [
    "DataLists = [0]  # generates empty list at index 0 because we want indexing to start at 1 \n",
    "                 # when I say #1, I want the first point, not the second point\n",
    "\n",
    "\n",
    "\n",
    "# the loop below goes through the dictionary in step 6.1 and processes the data\n",
    "for s in list(StrainNames.values()):\n",
    "    if not s == '':\n",
    "        DataLists.append(ProcessData(s)['Final']) # appends all data into a list of dataframes\n",
    "\n",
    "\n",
    "\n",
    "# the loop below assigns taps and plates to the processed data\n",
    "for df in DataLists[1:]: \n",
    "    assign_taps(df, tolerances)\n",
    "    insert_plates(df)\n",
    "\n",
    "\n",
    "\n",
    "print('done step 6.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time  dura   dist      prob     speed  plate      Date Plate_id  \\\n",
      "0  599.985  2.83  0.696  0.928571  0.245936      1  20220815  B0811ab   \n",
      "1  609.993  2.98  0.746  0.857143  0.250336      1  20220815  B0811ab   \n",
      "2  619.699  1.97  0.536  0.800000  0.272081      1  20220815  B0811ab   \n",
      "3  629.956  2.57  0.686  0.900000  0.266926      1  20220815  B0811ab   \n",
      "4  639.957  1.34  0.383  0.909091  0.285821      1  20220815  B0811ab   \n",
      "\n",
      "                          Screen  taps  \n",
      "0  PDScreen_TapHab_August15_2022   1.0  \n",
      "1  PDScreen_TapHab_August15_2022   2.0  \n",
      "2  PDScreen_TapHab_August15_2022   3.0  \n",
      "3  PDScreen_TapHab_August15_2022   4.0  \n",
      "4  PDScreen_TapHab_August15_2022   5.0  \n",
      "\n",
      "Shape of the first dataframe (Strain_1): (155, 10)\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the processed data for the first strain (displaying first 5 rows only)\n",
    "print(f\"Shape of the first dataframe (Strain_1): {DataLists[1].shape}\")\n",
    "print(\"\")\n",
    "DataLists[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Grouping Data and Naming\n",
    "\n",
    "This step takes all the individual strain data (processed in Step 6) and combines them into single dataframe, filters for time window 490s - 590s, drops unwanted columns. \n",
    "\n",
    "The final processed data `TotalConcatenated` is ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time  dura   dist      prob     speed  plate      Date Plate_id  \\\n",
      "0  599.985  2.83  0.696  0.928571  0.245936      1  20220815  B0811ab   \n",
      "1  609.993  2.98  0.746  0.857143  0.250336      1  20220815  B0811ab   \n",
      "2  619.699  1.97  0.536  0.800000  0.272081      1  20220815  B0811ab   \n",
      "3  629.956  2.57  0.686  0.900000  0.266926      1  20220815  B0811ab   \n",
      "4  639.957  1.34  0.383  0.909091  0.285821      1  20220815  B0811ab   \n",
      "\n",
      "                          Screen  taps dataset  \n",
      "0  PDScreen_TapHab_August15_2022   1.0      N2  \n",
      "1  PDScreen_TapHab_August15_2022   2.0      N2  \n",
      "2  PDScreen_TapHab_August15_2022   3.0      N2  \n",
      "3  PDScreen_TapHab_August15_2022   4.0      N2  \n",
      "4  PDScreen_TapHab_August15_2022   5.0      N2  \n",
      "done step 7\n"
     ]
    }
   ],
   "source": [
    "TotalConcatenated=pd.DataFrame()\n",
    "\n",
    "for d in range(1,len(np.unique(genotypes))+1):\n",
    "    TotalConcatenated=pd.concat([TotalConcatenated,\n",
    "                                 DataLists[d].assign(dataset=StrainNames.get(d))\n",
    "                                 ])\n",
    "\n",
    "TotalConcatenated.reset_index(inplace=False)\n",
    "\n",
    "TotalConcatenated['Screen']=Screen\n",
    "\n",
    "TotalConcatenated[['Gene', 'Allele']] = TotalConcatenated['dataset'].str.split('_', n=1, expand=True)\n",
    "\n",
    "TotalConcatenated['Allele']=TotalConcatenated['Allele'].fillna('N2')\n",
    "\n",
    "TotalConcatenated=TotalConcatenated.dropna()\n",
    "\n",
    "TotalConcatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done step 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe as `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as .csv!\n"
     ]
    }
   ],
   "source": [
    "TotalConcatenated.to_csv(f'{TotalConcatenated.Screen[0].values[0]}_tap_output.csv')\n",
    "print('saved as .csv!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A debugging cell to test for strain 'XJ1' (which is the old N2)\n",
    "print(TotalConcatenated[TotalConcatenated['Allele']=='XJ1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
