{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook UI to generate TAP data for MWT_Dashboards!\n",
    "\n",
    "### Beginner Essentials:\n",
    "1. Shift-Enter to run each cell. After you run, you should see an output \"done step #\". If not, an error has occured\n",
    "2. When inputting your own code/revising the code, make sure you close all your quotation marks '' and brackets (), [], {}.\n",
    "3. Don't leave any commas (,) hanging! (make sure an object always follows a comma. If there is nothing after a comma, remove the comma!\n",
    "4. Learning to code? Each line of code is annotated to help you understand how this code works!\n",
    "\n",
    "**Run all cells/steps sequentially, even the ones that do not need input**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Analysis of the Jupyter Notebook\n",
    "\n",
    "| Step | Purpose | Key Actions |\n",
    "|------|---------|-------------|\n",
    "| **1. Import Packages** | Load required Python libraries for data analysis | Imports `pandas`, `numpy`, `matplotlib`, etc. | \n",
    "| **2. Pick Filepath** | User input: select folder containing `.trv` files | Uses `FileChooser` widget to select directory | \n",
    "| **3. User-Defined Variables** | Set experiment parameters | Defines: `number_of_taps`, `ISI`,`first_tap`; Calculates `tolerances` (time windows for taps) | \n",
    "| **4. Construct Filelist** | Find all `.trv` files in selected folder | Sets working directory and scans `folder_path` using; Displays no. of `.trv` files found in the folder |\n",
    "| **5. Process Data Function** | Define functions to load and clean `.trv` data to use in step 6| - `ProcessData()`: Loads files, calculates metrics (reversal probability, speed)<br>- `assign_taps()`: Labels data with tap numbers <br>- `insert_plates()` |\n",
    "| **6.1 Process Data** | Apply processing to all strains| - Checks `filelist` for unique strain names (e.g., \"N2\") <br>- Runs `ProcessData()` and `assign_taps()` for each strain | \n",
    "| **7. Grouping & Naming** | Combine data from all strains | - Concatenates DataFrames<br>- Assigns dataset names (e.g., \"N2\") | \n",
    "| **Output CSV** | Save processed data | Exports `TotalConcatenated` to CSV (e.g., `PD_Screen_tap_output.csv`) |\n",
    "\n",
    "### Key Notes:\n",
    "- User Input Required: Steps 2 (file selection), 3 (parameters), 6.1 (strain verification)\n",
    "- Output: Final CSV contains all analyzed tap response data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages Required (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #<- package used to import and organize data\n",
    "import numpy as np #<- package used to import and organize data\n",
    "import math\n",
    "import os #<- package used to work with system file paths\n",
    "import seaborn as sns #<- package used to plot graphs\n",
    "from matplotlib import pyplot as plt #<- another package used to plot graphs\n",
    "from itertools import cycle #<- package used to iterate down rows (used in step 5 to add tap column)\n",
    "import ipywidgets as widgets #<- widget tool to generate button and tab for graphs\n",
    "from IPython.display import display #<- displays widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "# from tkinter import Tk, filedialog #<- Tkinter is a GUI package\n",
    "print(\"done step 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pick filepath (just run and click button from output)\n",
    "\n",
    "Run the following cell and click the button 'Select Folder' to pick a filepath.\n",
    "\n",
    "**Important: Later on, this script uses the total file path for each file to import and group data. That means if your folder has whatever your strain is named, the script will not work.**\n",
    "\n",
    "(ex. if your folder has \"N2\" in it this script sees all files inside this folder as having the \"N2\" search key)\n",
    "\n",
    "**An easy fix is to just rename your folder to something else (make your strains lower-case, or just have the date)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069ae3e8a3c640ab96d8072b8f99483b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Volumes', filename='', title='', show_hidden=False, select_desc='Select', change_desc='Chan…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starting_directory = '/Volumes'\n",
    "chooser = FileChooser(starting_directory)\n",
    "display(chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2\n"
     ]
    }
   ],
   "source": [
    "print(chooser.selected_path)\n",
    "folder_path=chooser.selected_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3eb2649ab54ac2b25d8da7447d31f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Screen:', options=('PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "screens = ['PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'Neuron_Genes_Screen']\n",
    "\n",
    "screen_chooser = widgets.Select(options=screens, value=screens[0], description='Screen:')\n",
    "display(screen_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Screen=screen_chooser.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User-Defined Variables (Add input here)\n",
    "\n",
    "Here, we add some constants to help you blaze through this code.\n",
    "\n",
    "3.1: Number of taps is pretty self-explanatory. How many taps does your experiment have? put in that number + 1 (N+1)!\n",
    "\n",
    "\n",
    "3.2: Change your ISI number. This will be reflected in the name/title of the output figure.\n",
    "\n",
    "\n",
    "**Note:** if you have different ISIs in the same folder, then come back and change this when you are graphing for the second set of data with the other ISI (Generally data from same ISIs are graphed together). If changing ISI mid-analysis, you can just skip straight to step 8 after running this cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Input\n",
    "number_of_taps = 30 # Taps in your experiment (N)\n",
    "\n",
    "# 3.2 Input\n",
    "ISI = 10  # ISI in your experiment\n",
    "first_tap = 600 # when is your first tap? check your TRV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap 1, tolerance: (598, 602)\n",
      "Tap 2, tolerance: (608, 612)\n",
      "Tap 3, tolerance: (618, 622)\n",
      "Tap 4, tolerance: (628, 632)\n",
      "Tap 5, tolerance: (638, 642)\n",
      "Tap 6, tolerance: (648, 652)\n",
      "Tap 7, tolerance: (658, 662)\n",
      "Tap 8, tolerance: (668, 672)\n",
      "Tap 9, tolerance: (678, 682)\n",
      "Tap 10, tolerance: (688, 692)\n",
      "Tap 11, tolerance: (698, 702)\n",
      "Tap 12, tolerance: (708, 712)\n",
      "Tap 13, tolerance: (718, 722)\n",
      "Tap 14, tolerance: (728, 732)\n",
      "Tap 15, tolerance: (738, 742)\n",
      "Tap 16, tolerance: (748, 752)\n",
      "Tap 17, tolerance: (758, 762)\n",
      "Tap 18, tolerance: (768, 772)\n",
      "Tap 19, tolerance: (778, 782)\n",
      "Tap 20, tolerance: (788, 792)\n",
      "Tap 21, tolerance: (798, 802)\n",
      "Tap 22, tolerance: (808, 812)\n",
      "Tap 23, tolerance: (818, 822)\n",
      "Tap 24, tolerance: (828, 832)\n",
      "Tap 25, tolerance: (838, 842)\n",
      "Tap 26, tolerance: (848, 852)\n",
      "Tap 27, tolerance: (858, 862)\n",
      "Tap 28, tolerance: (868, 872)\n",
      "Tap 29, tolerance: (878, 882)\n",
      "Tap 30, tolerance: (888, 892)\n",
      "Tap 31, tolerance: (1188, 1191)\n",
      "done step 3\n"
     ]
    }
   ],
   "source": [
    "# Here, open up one of the trv files to determine the times for each of these taps. \n",
    "\n",
    "# Record number of taps (N+1), e.g., if number_of_taps = 30, taps = [1, 2, 3, ..., 31]\n",
    "taps = np.arange(1, number_of_taps+2).tolist()\n",
    "\n",
    "# Assign tolerance to each tap\n",
    "lower = np.arange(first_tap-2, first_tap-2+(number_of_taps*ISI), ISI) # (first tap, last tap+10s, ISI)\n",
    "upper = np.arange(first_tap+2, first_tap+2+(number_of_taps*ISI), ISI) # (first tap, last tap+10s, ISI)\n",
    "tolerances = [(int(l), int(u)) for l, u in zip(lower, upper)]\n",
    "tolerances.append((1188,1191)) # (N+1)th tap\n",
    "\n",
    "# Display taps with tolerances \n",
    "for i in taps:\n",
    "    print(f\"Tap {i}, tolerance: {tolerances[i-1]}\")\n",
    "\n",
    "print(\"done step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Constructing Filelist From Source File/Select File (Just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .trv files to process: 5\n",
      "done step 4\n"
     ]
    }
   ],
   "source": [
    "#folder_path = '/Users/Joseph/Desktop/AVR14_10sISI' #- manual folder path if Tkinter is acting up\n",
    "\n",
    "os.chdir(folder_path) #<- setting your working directory so that your images will be saved here\n",
    "\n",
    "filelist = list() #<- empty list\n",
    "for root, dirs, files in os.walk(folder_path): #<- this for loop goes through your folder \n",
    "    for name in files:\n",
    "        if name.endswith('.trv'): # filters files with .trv (file that contains your data)\n",
    "            filepath = os.path.join(root, name) #<- Notes down the file path of each data file\n",
    "            filelist.append(filepath) #<- saves it into the list\n",
    "\n",
    "if not filelist:\n",
    "    raise FileNotFoundError(\"No .trv files found in the selected folder!\")\n",
    "else:\n",
    "    print(f\"Number of .trv files to process: {len(filelist)}\")\n",
    "    # print(f\"Example of first and last file saved: {filelist[0]}, {filelist[-1]}\") \n",
    "\n",
    "print('done step 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process Data Function (Just Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 5\n"
     ]
    }
   ],
   "source": [
    "def ProcessData(strain): \n",
    "    \"\"\"\n",
    "    Filters and processes .trv files matching the given strain.\n",
    "\n",
    "    Parameters: \n",
    "        strain (str): keyword to match in the files\n",
    "\n",
    "    Returns:\n",
    "        dict: N (Plate number) and Dataframe with required columns (\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\", \"Date\",\"Plate_id\",\"Screen\")\n",
    "\n",
    "    \"\"\"\n",
    "    strain_filelist = [x for x in filelist if strain in x] #<- goes through the list and filters for keyword\n",
    "    Strain_N = len(strain_filelist) # Finds the number of plates per strain\n",
    "    if Strain_N == 0:\n",
    "        raise AssertionError ('{} is not a good identifier as number of plates = 0'.format(strain))\n",
    "    else:\n",
    "        pass\n",
    "        print(f'Strain {strain}')\n",
    "        print(f'Number of plates: {Strain_N}') \n",
    "\n",
    "        # visiting files in this strain\n",
    "        strain_filelist = [file for file in filelist if strain in file]\n",
    "        df_list=[]\n",
    "        for file in strain_filelist:\n",
    "            if file.split('/')[-1].startswith('._'):\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"File: {file}\")\n",
    "                df= pd.read_csv(file, sep=' ', header = None, encoding_errors='ignore')\n",
    "                df['Plate_id'] = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "                df['Date'] = file.split('/')[-2].split('_')[0]\n",
    "                df['Screen'] = file.split('/')[-4]\n",
    "                df_list.append(df)\n",
    "        DF_Total = pd.concat(df_list, ignore_index = True)\n",
    "\n",
    "    # for f in strain_filelist:\n",
    "    #     DF_Total = pd.concat(pd.read_csv(f, sep=' ', skiprows = 4, header = None))\n",
    "    #     DF_Total = pd.concat([pd.read_csv(f, sep=' ', header = None, encoding_errors='ignore') for f in strain_filelist],\n",
    "    #                   ignore_index=True) #<- imports your data files\n",
    "    #     DF_Total = DF_Total.dropna(axis = 1) #<- cleans your data\n",
    "        \n",
    "        # column names for trv files\n",
    "        DF_Total = DF_Total.rename( #<- more cleaning\n",
    "                    {0:'time',\n",
    "                    2:'rev_before',\n",
    "                    3:'no_rev',\n",
    "                    4:'stim_rev',\n",
    "                    7:'dist',\n",
    "                    8:'dist_std',\n",
    "                    9:'dist_stderr',\n",
    "                    11:'dist_0th',\n",
    "                    12:'dist_1st',\n",
    "                    13:'dist_2nd',\n",
    "                    14:'dist_3rd',\n",
    "                    15:'dist_100th',\n",
    "                    18:'dura',\n",
    "                    19:'dura_std',\n",
    "                    20:'dura_stderr',\n",
    "                    22:'dura_0th',\n",
    "                    23:'dura_1st',\n",
    "                    24:'dura_2nd',\n",
    "                    25:'dura_3rd',\n",
    "                    26:'dura_100th'}, axis=1)\n",
    "        \n",
    "        # check function here for NaN Columns\n",
    "        DF_Total['plate'] = 0\n",
    "\n",
    "        # Calculate reversal probability \n",
    "        DF_Total['prob'] = DF_Total['stim_rev']/ (DF_Total['no_rev'] + DF_Total['stim_rev']) \n",
    "\n",
    "        # Calculate speed\n",
    "        DF_Total['speed'] = DF_Total['dist']/DF_Total['dura']\n",
    "\n",
    "        DF_Total_rows = int(DF_Total.shape[0])\n",
    "        print(f'This strain/treatment has {DF_Total_rows} total taps') # Outputs as the second number. Check if you are missing taps!\n",
    "\n",
    "        DF_Final = DF_Total[[\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\", \"Date\",\"Plate_id\",\"Screen\"]].copy()\n",
    "\n",
    "        print(\"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    return{\n",
    "            'N': Strain_N,\n",
    "            'Confirm':DF_Total,\n",
    "            'Final': DF_Final}\n",
    "\n",
    "\n",
    "\n",
    "def assign_taps(df, tolerances):\n",
    "    \"\"\"\n",
    "    Assigns tap number to each row in the DataFrame based on time tolerances.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to modify\n",
    "        tolerances (list of tuples): Each tuple is (lower, upper) time range\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df['taps'] = np.nan\n",
    "    for taps, tolerance in enumerate(tolerances): #[(99, 101), (109,111), ...]\n",
    "        tap_lower,tap_upper = tolerance\n",
    "        TimesInTapRange = df['time'].between(tap_lower,tap_upper, inclusive=\"both\")\n",
    "        df.loc[TimesInTapRange,'taps'] = taps+1 # set the tap to i where times are between\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def insert_plates(df):   \n",
    "    \"\"\"\n",
    "    Inserts a plate column into a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): any dataframe\n",
    "    \n",
    "    Returns: \n",
    "        pd.DataFrame: dataframe with a plate column\n",
    "    \"\"\"\n",
    "    df['plate']=(df['taps'] ==1).cumsum()\n",
    "\n",
    "\n",
    "            \n",
    "print('done step 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Process Data (PLEASE READ, Add input here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the hardest part - from your naming convention, pick a unique identifier for each group.\n",
    "\n",
    "This means that all of names of your files for that strain should have that in common but is not common across other files! If you did a good job naming your files and following a good naming convention, this should be easy.\n",
    "\n",
    "**Be careful and really look hard in your naming structure. Note you want an unique identifier in the entire file path for the same group of files. An easy mistake is to have the strain name in the overall folder name, in this case if you use your strain name as a keyword it would include all files in that folder!**\n",
    "\n",
    "For example, if all your N2 files have a certain pattern like \"N2_5x4\" in this following example:\n",
    "'/Users/Joseph/Desktop/AVR14_10sISI_TapHab_0710_2019/N2/20190710_141740/N2_5x4_f94h20c_100s30x10s10s_C0710ab.trv'\n",
    "Then you need to set that identifier for the strain keyword:\n",
    "'Strain_1' = 'N2_5x4'\n",
    "\n",
    "#### Depending on how many strains you are running for comparison, you may need to add/delete some lines!\n",
    "\n",
    "* You are not naming your data groups here, we have a step for that later!\n",
    "* Here, you want to note down ALL the strains you have in the folder\n",
    "* If you have just 2 strains, add hashtags (#) in front of the lines you do not need.\n",
    "If you need more strains, just add more lines, following the same format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genotypes in the experiment: 1\n",
      "1: N2\n"
     ]
    }
   ],
   "source": [
    "genotype=[]\n",
    "for f in filelist:\n",
    "    genotype.append(f.split('/')[-3])\n",
    "\n",
    "genotypes=np.unique(genotype)\n",
    "\n",
    "StrainNames=dict(enumerate(genotypes,1))\n",
    "\n",
    "print(f\"Number of genotypes/strains in the experiment: {len(genotypes)}\")\n",
    "\n",
    "# Display the first 5 Strain names in the experiment\n",
    "for k in list(StrainNames)[:5]:\n",
    "    print(f\"{k}: {StrainNames[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.str_('N2')]\n",
      "<class 'list'>\n",
      "<class 'numpy.str_'>\n",
      "done step 6.1\n"
     ]
    }
   ],
   "source": [
    "print(list(StrainNames.values()))\n",
    "print(type(list(StrainNames.values())))\n",
    "print(type(list(StrainNames.values())[0]))\n",
    "print('done step 6.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Process Data (just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Volumes/JOSEPH/PD_Screen/F53B2.5_ok226/20220524_141642/ZE1_10x2_f72h20C_600s31x10s10s_B0520ba.trv') as f:\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strain N2\n",
      "Number of plates: 5\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_101538/N2_10x2_f72h20C_600s31x10s10s_B0811ab.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_102652/N2_10x2_f96h20C_600s31x10s10s_A0811aa.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_122801/N2_10x2_f96h20C_600s31x10s10s_A0811ad.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_121502/N2_10x2_f72h20C_600s31x10s10s_B0811ae.trv\n",
      "File: /Users/gurmehak/Documents/RankinLab/Test_Datasets/PDScreen_TapHab_August15_2022/N2/20220815_103433/N2_10x2_f72h20C_600s31x10s10s_C0811ac.trv\n",
      "This strain/treatment has 155 total taps\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "done step 6.2\n"
     ]
    }
   ],
   "source": [
    "# import threading\n",
    "\n",
    "DataLists = [0]  # generates empty list at index 0 because we want indexing to start at 1 \n",
    "                 # when I say #1, I want the first point, not the second point\n",
    "\n",
    "\n",
    "\n",
    "# the loop below goes through the dictionary in step 6.1 and processes the data\n",
    "for s in list(StrainNames.values()):\n",
    "    if not s == '':\n",
    "        # threading.Thread(target=DataLists.append(ProcessData(s)['Final'])).start()\n",
    "        DataLists.append(ProcessData(s)['Final']) # appends all data into a list of dataframes\n",
    "\n",
    "\n",
    "\n",
    "# the loop below assigns taps and plates to the processed data\n",
    "for df in DataLists[1:]: \n",
    "    assign_taps(df, tolerances)\n",
    "    insert_plates(df)\n",
    "\n",
    "\n",
    "\n",
    "print('done step 6.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLists.append(ProcessData('vps-35_ok1880')['Final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time  dura   dist      prob     speed  plate      Date Plate_id  \\\n",
      "0  599.985  2.83  0.696  0.928571  0.245936      1  20220815  B0811ab   \n",
      "1  609.993  2.98  0.746  0.857143  0.250336      1  20220815  B0811ab   \n",
      "2  619.699  1.97  0.536  0.800000  0.272081      1  20220815  B0811ab   \n",
      "3  629.956  2.57  0.686  0.900000  0.266926      1  20220815  B0811ab   \n",
      "4  639.957  1.34  0.383  0.909091  0.285821      1  20220815  B0811ab   \n",
      "\n",
      "                          Screen  taps  \n",
      "0  PDScreen_TapHab_August15_2022   1.0  \n",
      "1  PDScreen_TapHab_August15_2022   2.0  \n",
      "2  PDScreen_TapHab_August15_2022   3.0  \n",
      "3  PDScreen_TapHab_August15_2022   4.0  \n",
      "4  PDScreen_TapHab_August15_2022   5.0  \n",
      "\n",
      "Shape of the first dataframe (Strain_1): (155, 10)\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the processed data for the first strain (displaying first 5 rows only)\n",
    "print(DataLists[1].head())\n",
    "print(\"\")\n",
    "print(f\"Shape of the first dataframe (Strain_1): {DataLists[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Grouping Data and Naming (Optional: Add input here)\n",
    "\n",
    "Here, you get to name your data groups/strain! Name your groups however you like under between the quotation marks for each strain.\n",
    "\n",
    "For example: If your Strain1 is N2 and you wish for the group to be called N2,\n",
    "your line should look like:\n",
    "\n",
    "DataLists[x].assign(dataset = 'N2')\n",
    "\n",
    "## Go back to step 6.1 to check which strain is which item on the DataLists.\n",
    "In this example, the first item on DataLists is N2.\n",
    "\n",
    "\n",
    "## Remember: Put your name in quotes. (ex: 'N2' and not N2)\n",
    "\n",
    "As default, the names are set to the unique identifier labels.\n",
    "\n",
    "## Depending on the number of strains you are running the comparison, you may have to delete/add lines of code (following the same format). \n",
    "## Remember to add/delete commas too.\n",
    "\n",
    "# If you want to change your groups, you do that here. \n",
    "For example, if you have 5 strains in your folder but only want to compare between 2 or 3 strains, designate that here and follow through with steps 6 and 7. Once you are done, come back to step 6 and change your groups again (You are going to have to change your graph titles for the second run-through though)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time  dura   dist      prob     speed  plate      Date Plate_id  \\\n",
      "0     599.985  2.83  0.696  0.928571  0.245936      1  20220815  B0811ab   \n",
      "1     609.993  2.98  0.746  0.857143  0.250336      1  20220815  B0811ab   \n",
      "2     619.699  1.97  0.536  0.800000  0.272081      1  20220815  B0811ab   \n",
      "3     629.956  2.57  0.686  0.900000  0.266926      1  20220815  B0811ab   \n",
      "4     639.957  1.34  0.383  0.909091  0.285821      1  20220815  B0811ab   \n",
      "..        ...   ...    ...       ...       ...    ...       ...      ...   \n",
      "150   859.968  1.35  0.309  0.315789  0.228889      5  20220815  C0811ac   \n",
      "151   869.969  1.16  0.288  0.357143  0.248276      5  20220815  C0811ac   \n",
      "152   879.969  2.01  0.533  0.444444  0.265174      5  20220815  C0811ac   \n",
      "153   889.967  0.87  0.202  0.342857  0.232184      5  20220815  C0811ac   \n",
      "154  1189.966  2.01  0.561  0.607143  0.279104      5  20220815  C0811ac   \n",
      "\n",
      "                            Screen  taps dataset  \n",
      "0    PDScreen_TapHab_August15_2022   1.0      N2  \n",
      "1    PDScreen_TapHab_August15_2022   2.0      N2  \n",
      "2    PDScreen_TapHab_August15_2022   3.0      N2  \n",
      "3    PDScreen_TapHab_August15_2022   4.0      N2  \n",
      "4    PDScreen_TapHab_August15_2022   5.0      N2  \n",
      "..                             ...   ...     ...  \n",
      "150  PDScreen_TapHab_August15_2022  27.0      N2  \n",
      "151  PDScreen_TapHab_August15_2022  28.0      N2  \n",
      "152  PDScreen_TapHab_August15_2022  29.0      N2  \n",
      "153  PDScreen_TapHab_August15_2022  30.0      N2  \n",
      "154  PDScreen_TapHab_August15_2022  31.0      N2  \n",
      "\n",
      "[155 rows x 11 columns]\n",
      "done step 7\n"
     ]
    }
   ],
   "source": [
    "TotalConcatenated=pd.DataFrame()\n",
    "for d in range(1,len(np.unique(genotypes))+1):\n",
    "    TotalConcatenated=pd.concat([TotalConcatenated,\n",
    "                                 DataLists[d].assign(dataset=StrainNames.get(d))])\n",
    "\n",
    "TotalConcatenated.reset_index(inplace=False)\n",
    "print(TotalConcatenated)\n",
    "\n",
    "#if TotalConcatenated[\"taps\"].loc[ind] is not 1:\n",
    "#   TotalConcatenated[\"taps\"].loc[ind:indices[c+1]] = list(range(1,len(TotalConcatenated[\"taps\"].loc[ind:indices[c+1]])+1))\n",
    "# missing_taps(TotalConcatenated, accurate_taps, tolerances)\n",
    "\n",
    "print('done step 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Colour Palette - Only run the below cell ONCE\n",
    "\n",
    "The following code sets the colour palette for the whole experiment - and then designate one colour to each strain. After this, if as you are graphing you take away some strains, you can do so with the colours still matching accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time  dura   dist      prob     speed  plate      Date Plate_id  \\\n",
      "0     599.985  2.83  0.696  0.928571  0.245936      1  20220815  B0811ab   \n",
      "1     609.993  2.98  0.746  0.857143  0.250336      1  20220815  B0811ab   \n",
      "2     619.699  1.97  0.536  0.800000  0.272081      1  20220815  B0811ab   \n",
      "3     629.956  2.57  0.686  0.900000  0.266926      1  20220815  B0811ab   \n",
      "4     639.957  1.34  0.383  0.909091  0.285821      1  20220815  B0811ab   \n",
      "..        ...   ...    ...       ...       ...    ...       ...      ...   \n",
      "150   859.968  1.35  0.309  0.315789  0.228889      5  20220815  C0811ac   \n",
      "151   869.969  1.16  0.288  0.357143  0.248276      5  20220815  C0811ac   \n",
      "152   879.969  2.01  0.533  0.444444  0.265174      5  20220815  C0811ac   \n",
      "153   889.967  0.87  0.202  0.342857  0.232184      5  20220815  C0811ac   \n",
      "154  1189.966  2.01  0.561  0.607143  0.279104      5  20220815  C0811ac   \n",
      "\n",
      "        Screen  taps dataset  \n",
      "0    PD_Screen   1.0      N2  \n",
      "1    PD_Screen   2.0      N2  \n",
      "2    PD_Screen   3.0      N2  \n",
      "3    PD_Screen   4.0      N2  \n",
      "4    PD_Screen   5.0      N2  \n",
      "..         ...   ...     ...  \n",
      "150  PD_Screen  27.0      N2  \n",
      "151  PD_Screen  28.0      N2  \n",
      "152  PD_Screen  29.0      N2  \n",
      "153  PD_Screen  30.0      N2  \n",
      "154  PD_Screen  31.0      N2  \n",
      "\n",
      "[155 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(TotalConcatenated['dataset'].str.split(\"_\", n=1, expand=True))\n",
    "TotalConcatenated['Screen']=Screen\n",
    "print(TotalConcatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mTotalConcatenated\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGene\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAllele\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m = TotalConcatenated[\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m].str.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m, n=\u001b[32m1\u001b[39m, expand=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(TotalConcatenated)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/rankinlab/lib/python3.11/site-packages/pandas/core/frame.py:4299\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4297\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_frame(key, value)\n\u001b[32m   4298\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np.ndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[32m-> \u001b[39m\u001b[32m4299\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4300\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[32m   4301\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_item_frame_value(key, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/rankinlab/lib/python3.11/site-packages/pandas/core/frame.py:4341\u001b[39m, in \u001b[36mDataFrame._setitem_array\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4337\u001b[39m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[32m   4338\u001b[39m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[32m   4340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m4341\u001b[39m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4342\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value.columns):\n\u001b[32m   4343\u001b[39m             \u001b[38;5;28mself\u001b[39m[k1] = value[k2]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/rankinlab/lib/python3.11/site-packages/pandas/core/indexers/utils.py:390\u001b[39m, in \u001b[36mcheck_key_length\u001b[39m\u001b[34m(columns, key, value)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m columns.is_unique:\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value.columns) != \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mColumns must be same length as key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    392\u001b[39m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns.get_indexer_non_unique(key)[\u001b[32m0\u001b[39m]) != \u001b[38;5;28mlen\u001b[39m(value.columns):\n",
      "\u001b[31mValueError\u001b[39m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "TotalConcatenated[['Gene', 'Allele']] = TotalConcatenated['dataset'].str.split('_', n=1, expand=True)\n",
    "print(TotalConcatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated['Allele']=TotalConcatenated['Allele'].fillna('N2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated=TotalConcatenated.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated.to_csv(f'{TotalConcatenated.Screen[0].values[0]}_tap_output.csv')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A debugging cell to test for strain 'XJ1' (which is the old N2)\n",
    "print(TotalConcatenated[TotalConcatenated['Allele']=='XJ1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rankinlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
