{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8b6eb7",
   "metadata": {},
   "source": [
    "# 1. Imports and File selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf3cc6-37e8-43e4-a57e-d9f3d868ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import numpy\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "import sys\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "from config import load_config\n",
    "from ipyfilechooser import FileChooser\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlite3 import Error\n",
    "from sqlite3 import IntegrityError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f838815",
   "metadata": {},
   "source": [
    "## Select Baseline .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047872c-f454-4b21-ae5f-fbe76ded5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_directory = '/Volumes'\n",
    "baseline_chooser = FileChooser(starting_directory)\n",
    "display(baseline_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae9075",
   "metadata": {},
   "source": [
    "## Select Tap .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf95420-e48d-4d6d-964f-dbbc41cc0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_chooser=FileChooser('/Volumes')\n",
    "display(tap_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c039e",
   "metadata": {},
   "source": [
    "## Select Post Stimulus Arousal .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83263b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "psa_chooser = FileChooser('/Volumes')\n",
    "display(psa_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "screens = ['PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', \n",
    "           'Neuron_Genes_Screen', 'PD_GWAS_Locus71_Screen', 'ASD_WGS_Screen', 'Miscellaneous']\n",
    "\n",
    "screen_chooser = widgets.Select(options=screens, value=screens[0], description='Screen:')\n",
    "display(screen_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad41b49-c54a-41bc-b2a4-12865e70cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Screen=screen_chooser.value\n",
    "folder_path=baseline_chooser.selected_path\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f30cec",
   "metadata": {},
   "source": [
    "## Read baseline, tap and post stimulus arousal (psa) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdae795-4e5b-4371-acd2-40d77be2796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the baseline file\n",
    "baseline_output = pd.read_csv(baseline_chooser.selected, index_col=0)#.drop(columns=['index'])\n",
    "\n",
    "print(f\"\\nShape of the baseline .csv file: {baseline_output.shape}\")\n",
    "\n",
    "# Print the first five rows of the file\n",
    "baseline_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3581dfb-50a2-41f2-87d2-5ca53439c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tap file\n",
    "tap_output = pd.read_csv(tap_chooser.selected, index_col=0)\n",
    "\n",
    "print(f\"\\nShape of the psa .csv file: {tap_output.shape}\")\n",
    "\n",
    "# Print the first five rows of the file\n",
    "tap_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the psa file\n",
    "psa_output = pd.read_csv(psa_chooser.selected, index_col=0)\n",
    "\n",
    "for cols in ['Instantaneous Speed', 'Interval Speed',\n",
    "       'Bias', 'Morphwidth', 'Midline', 'Area', 'Angular Speed',\n",
    "       'Aspect Ratio', 'Kink', 'Curve', 'Crab', 'Pathlength']:\n",
    "    psa_output.rename(columns={cols: f\"PSA {cols}\"}, inplace=True)\n",
    "\n",
    "print(f\"\\nShape of the tap .csv file: {psa_output.shape}\")\n",
    "\n",
    "# Print the first five rows of the file\n",
    "psa_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a04ec",
   "metadata": {},
   "source": [
    "### Merge PSA with Tap response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eeee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_psa_output = pd.merge(\n",
    "    tap_output, psa_output.drop(columns=['Experiment', 'Time', 'Tap', 'PSA Morphwidth', \n",
    "                                         'PSA Midline', 'PSA Area', 'PSA Angular Speed',]),\n",
    "    how='outer', \n",
    "    on=['dataset', 'Gene', 'Allele', 'Date', 'Plate_id', 'Screen', \"taps\" ] \n",
    ")\n",
    "\n",
    "tap_psa_output = tap_psa_output[['dataset', 'Gene', 'Allele', 'Date', 'Plate_id', 'plate', \n",
    "                                 'Screen', 'taps', 'time', 'dura', 'dist', 'prob', 'speed',\n",
    "                                 'PSA Instantaneous Speed', 'PSA Interval Speed', 'PSA Bias',\n",
    "                                 'PSA Aspect Ratio', 'PSA Kink', 'PSA Curve', 'PSA Crab'\n",
    "                                 ]]\n",
    "\n",
    "print(f\"Shape of the dataframe: {tap_psa_output.shape}\")\n",
    "\n",
    "tap_psa_output.rename(columns={\n",
    "    'prob': 'Probability',\n",
    "    'dura': 'Duration',\n",
    "    'speed': 'Speed'\n",
    "}, inplace=True)\n",
    "\n",
    "tap_psa_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85813fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tap_psa_output.to_csv(\"tap_psa_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee66b8",
   "metadata": {},
   "source": [
    "# 2. DataFrame preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7fca4",
   "metadata": {},
   "source": [
    "### 2.1. Tap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e014e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for first tap\n",
    "PD_first_tap = (\n",
    "    tap_output[(tap_output.taps==1)]\n",
    "    .reset_index().drop(columns=\"index\")\n",
    "    .rename(columns={\"dura\": \"init_dura\", \"prob\": \"init_prob\", \"speed\": \"init_speed\"}, errors=\"raise\")\n",
    ")\n",
    "\n",
    "PD_first_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for recovery taps\n",
    "PD_recov_taps = (\n",
    "    tap_output[(tap_output.taps==31)]\n",
    "    .reset_index().drop(columns=\"index\")\n",
    "    .rename(columns={\"dura\": \"recov_dura\", \"prob\": \"recov_prob\", \"speed\":\"recov_speed\"})\n",
    ")\n",
    "\n",
    "PD_recov_taps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10272023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for last three taps\n",
    "PD_final_taps = (\n",
    "    tap_output[((tap_output.taps >= 28) & (tap_output.taps <= 30))]\n",
    "    .groupby([\"dataset\", \"Date\",\"Plate_id\",\"Screen\",\"Gene\",\"Allele\",\"plate\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"dura\": \"final_dura\", \"prob\": \"final_prob\", \"speed\": \"final_speed\"}, errors=\"raise\")\n",
    ")\n",
    "\n",
    "PD_final_taps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to analyse habituation behaviour after merging first tap and final taps\n",
    "\n",
    "PD_habit_levels = pd.merge(\n",
    "    PD_first_tap, \n",
    "    PD_final_taps, \n",
    "    on =['dataset', 'plate', \"Plate_id\", \"Screen\", \"Gene\", \"Allele\", \"Date\"], how ='left'\n",
    ").drop(columns=['time_x','time_y','dist_x','dist_y', 'taps_x', 'taps_y']).dropna()\n",
    "\n",
    "PD_habit_levels['habit_dura'] = PD_habit_levels['init_dura'] - PD_habit_levels['final_dura']\n",
    "\n",
    "PD_habit_levels['habit_prob'] = PD_habit_levels['init_prob'] - PD_habit_levels['final_prob']\n",
    "\n",
    "PD_habit_levels['habit_speed'] = PD_habit_levels['init_speed'] - PD_habit_levels['final_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cec40a-82bb-4783-a0a9-fa6d9fcfa6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to analyse habituation behaviour after merging with recovery taps\n",
    "\n",
    "if PD_recov_taps.empty:\n",
    "    PD_habituation = pd.merge(PD_habit_levels, PD_recov_taps, on =['dataset','plate',\"Plate_id\",\"Screen\",\"Gene\",\"Allele\",\"Date\"], how ='outer')\n",
    "else:\n",
    "    PD_habituation = pd.merge(PD_habit_levels, PD_recov_taps, on =['dataset','plate',\"Plate_id\",\"Screen\",\"Gene\",\"Allele\",\"Date\"], how ='left')\n",
    "\n",
    "if Screen not in ['Neuron_Genes_Screen', 'G-Proteins_Screen']:\n",
    "    PD_habituation = PD_habituation.dropna() \n",
    "\n",
    "PD_habituation['recovery_dura']=(PD_habituation.recov_dura-PD_habituation.init_dura)/PD_habituation.init_dura*100\n",
    "\n",
    "PD_habituation['recovery_prob']=(PD_habituation.recov_prob-PD_habituation.init_prob)/PD_habituation.init_prob*100\n",
    "\n",
    "PD_habituation['recovery_speed']=(PD_habituation.recov_speed-PD_habituation.init_speed)/PD_habituation.init_speed*100\n",
    "\n",
    "PD_habituation['memory_retention_dura']=(PD_habituation.recov_dura-PD_habituation.final_dura)\n",
    "\n",
    "PD_habituation['memory_retention_prob']=(PD_habituation.recov_prob-PD_habituation.final_prob)\n",
    "\n",
    "PD_habituation['memory_retention_speed']=(PD_habituation.recov_speed-PD_habituation.final_speed)\n",
    "\n",
    "\n",
    "# Rename `PD_habituation` to `tap_data` based on the condition below\n",
    "if Screen in ['Neuron_Genes_Screen', 'G-Proteins_Screen']:\n",
    "    tap_data=PD_habituation.dropna(subset = ['init_dura', 'init_prob', 'init_speed', 'plate', 'Date', 'Plate_id',\n",
    "       'Screen', 'dataset', 'Gene', 'Allele', 'final_dura', 'final_prob',\n",
    "       'final_speed', 'habit_dura', 'habit_prob', 'habit_speed'])\n",
    "else:\n",
    "    tap_data=PD_habituation.dropna() \n",
    "\n",
    "\n",
    "# Display final dataframe\n",
    "tap_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b18cff",
   "metadata": {},
   "source": [
    "### 2.2. PSA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate Initial, Final, Peak, ect values for specified column (metric)\n",
    "\n",
    "def summary_metrics(df, metric = 'Instantaneous Speed'):\n",
    "\n",
    "    initial = df[metric].iloc[0]\n",
    "    recovery = df[metric].iloc[-1]\n",
    "    final = df[metric].iloc[-4:-1].mean() # average of the last three taps\n",
    "    peak = df[metric].max()\n",
    "    peak_id = df[metric].values.argmax() # only used for peak tap calculation\n",
    "    peak_tap = df['taps'].iloc[peak_id]\n",
    "    mean = df[metric].mean()\n",
    "    sensitization = peak - initial\n",
    "    habituation = peak - final \n",
    "    spontaneous_recovery = 100*(initial - recovery)/initial if metric not in ['PSA Aspect Ratio', 'PSA Kink', 'PSA Curve', 'PSA Crab'] else 100*(recovery - initial)/initial\n",
    "    memory_retention = final - recovery if metric not in ['PSA Aspect Ratio', 'PSA Kink', 'PSA Curve', 'PSA Crab'] else recovery - final\n",
    "    # initial_to_peak = df[metric].iloc[: peak_id+1].mean()\n",
    "    # peak_to_recovery = df[metric].iloc[peak_id:].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    return pd.Series({\n",
    "        f'Initial {metric}': initial, \n",
    "        f'Final {metric}': final,\n",
    "        f'Recovery {metric}': recovery, \n",
    "        f'Peak {metric}': peak,\n",
    "        f'Peak Tap Number {metric}': peak_tap,\n",
    "        f'Average {metric}': mean,\n",
    "        f'Sensitization {metric}': sensitization,\n",
    "        f'Habituation {metric}': habituation,\n",
    "        f'Spontaneous Recovery {metric}': spontaneous_recovery,\n",
    "        f'Memory Retention {metric}': memory_retention\n",
    "        # f'Initial_to_peak {metric}': initial_to_peak, \n",
    "        # f'Peak_to_recovery {metric}': peak_to_recovery\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2451917",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# columns to summarize\n",
    "metrics_to_summarize = ['PSA Instantaneous Speed', 'PSA Bias', 'PSA Angular Speed', \n",
    "                        'PSA Aspect Ratio', 'PSA Kink', 'PSA Curve', 'PSA Crab']\n",
    "\n",
    "# standard columns\n",
    "group_cols = ['Experiment', 'Plate_id', 'Date', 'Screen', 'dataset', 'Gene', 'Allele']\n",
    "\n",
    "# pass each column to summarise through `summary_metrics` function and merge the summarised values to psa_output\n",
    "psa_data = psa_output[group_cols].drop_duplicates()\n",
    "for metric in metrics_to_summarize:\n",
    "    summary = psa_output.groupby(group_cols).apply(lambda x: summary_metrics(x, metric)).reset_index()\n",
    "    psa_data = pd.merge(psa_data, summary, on=group_cols, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f909ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "psa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e459572",
   "metadata": {},
   "outputs": [],
   "source": [
    "psa_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74308e12-a414-4899-b18f-ed97d006930d",
   "metadata": {},
   "source": [
    "# 3. Run Statistics (T-Test and mean sample distance) on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f35b2",
   "metadata": {},
   "source": [
    "## 3.1 Generate dataframes conditioned by `baseline` (True/False) and `allele` (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76fdc5-2356-4617-8c2c-29e1685808bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_byplate(output, baseline=[\"true\", \"false\", \"psa\"], allele = [False, True]):\n",
    "    \"\"\"\n",
    "    Aggregates data by 'Gene' or 'Allele' and drops 'Plate_id','Date','Screen','dataset', etc\n",
    "\n",
    "    Parameters:\n",
    "        output (pd.DataFrame): Input DataFrame (either baseline_output or tap_data)\n",
    "        baseline (boolean): whether data is baseline (True) or tap response (False)\n",
    "        allele (boolean): group by allele (True) or group by gene (False)\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with plate-level averages\n",
    "    \"\"\"\n",
    "    \n",
    "    # columns to delete if baseline = true\n",
    "    if baseline == \"true\":\n",
    "        drop_col = ['Plate_id','n','Number','Time','Screen','Date','Allele']\n",
    "    # columns to delete if baseline = false\n",
    "    elif baseline == \"false\":\n",
    "        drop_col = ['Plate_id','Screen','Date','Allele','dist','plate','time',\n",
    "                       'taps','recov_dura','recov_prob','recov_speed']\n",
    "    # columns to delete if baseline = psa\n",
    "    else: \n",
    "        drop_col = ['Experiment', 'Plate_id', 'Date', 'Screen', 'Allele']\n",
    "\n",
    "    drop_col.append('Gene') if allele else drop_col.append('dataset')\n",
    "     \n",
    "    output_byplate = output.groupby(\n",
    "        by=['Plate_id','Date','Screen','dataset','Gene','Allele'],\n",
    "        as_index=False).mean().drop(columns=drop_col)\n",
    "    \n",
    "    return output_byplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc76ca",
   "metadata": {},
   "source": [
    "#### 3.1.1 `baseline` = True, `allele` = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_output_byplate=get_output_byplate(baseline_output, baseline= \"true\", allele=False)\n",
    "\n",
    "print(f\"Shape: {baseline_output_byplate.shape}\")\n",
    "\n",
    "baseline_output_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e0c7f",
   "metadata": {},
   "source": [
    "#### 3.1.2 `baseline` = False, `allele` = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_data_byplate=get_output_byplate(tap_data, baseline=\"false\", allele=False)\n",
    "\n",
    "print(f\"Shape: {tap_data_byplate.shape}\")\n",
    "\n",
    "tap_data_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21990731",
   "metadata": {},
   "source": [
    "#### 3.1.3 `baseline` = True, `allele` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49800e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_output_allele_byplate = get_output_byplate(baseline_output,baseline=\"true\", allele=True)\n",
    "\n",
    "print(f\"Shape: {baseline_output_allele_byplate.shape}\")\n",
    "\n",
    "baseline_output_allele_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc810907",
   "metadata": {},
   "source": [
    "#### 3.1.4 `baseline` = False, `allele` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_data_allele_byplate = get_output_byplate(tap_data, baseline=\"false\", allele=True)\n",
    "\n",
    "print(f\"Shape: {tap_data_allele_byplate.shape}\")\n",
    "\n",
    "tap_data_allele_byplate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304d782-9424-4068-a3f4-4982b1be21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tap_data_allele_byplate[tap_data_allele_byplate.dataset=='N2_XJ1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf35d1",
   "metadata": {},
   "source": [
    "#### 3.1.5 `baseline` = \"psa\" , `allele` = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "psa_data_byplate = get_output_byplate(psa_data, baseline=\"psa\", allele=False)\n",
    "\n",
    "print(f\"Shape: {psa_data_byplate.shape}\")\n",
    "\n",
    "psa_data_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052ac41",
   "metadata": {},
   "source": [
    "#### 3.1.6 `baseline` = \"psa\" , `allele` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82acc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psa_data_allele_byplate = get_output_byplate(psa_data, baseline=\"psa\", allele=True)\n",
    "\n",
    "print(f\"Shape: {psa_data_allele_byplate.shape}\")\n",
    "\n",
    "psa_data_allele_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33e2a9",
   "metadata": {},
   "source": [
    "## 3.2 Calculate Mean Distances and CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10502cca-0ab9-4bd5-9801-7a247a6af822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_phenotypes(df):\n",
    "    ''' \n",
    "    Splits a multi-column DataFrame into a list of DataFrames, each containing one phenotype\n",
    "\n",
    "    input: \n",
    "        df (pd.DataFrame): dataframe with multiple columns (1st column is the index, the other are phenotypes)\n",
    "\n",
    "    returns:\n",
    "        list_phenotypes_df: list with 2 columns - one for index and one for phenotype, \n",
    "            for how many phenotypes there are in the input\n",
    "    '''\n",
    "    list_phenotypes_df = []\n",
    "    index = df.columns[0]\n",
    "    for i in df.columns[1:]:\n",
    "        list_phenotypes_df.append(df[[index, i]].copy())\n",
    "\n",
    "    return list_phenotypes_df\n",
    "\n",
    "\n",
    "\n",
    "def ci95(df):\n",
    "    \"\"\"\n",
    "    input: df of 4 columns: index, mean, count, std\n",
    "\n",
    "    returns: df of 6 columns: index, mean, count, std, ci95_hi, ci95_low\n",
    "\n",
    "    \"\"\"\n",
    "    for metric in df.columns.levels[0]:\n",
    "        if metric == 'Gene':\n",
    "            pass\n",
    "        else:\n",
    "            ci95_hi = []\n",
    "            ci95_lo = []\n",
    "            for i in df[metric].index:\n",
    "                m = df[metric]['mean'].loc[i]\n",
    "                c = df[metric]['count'].loc[i]\n",
    "                s = df[metric]['sem'].loc[i]\n",
    "                ci95_hi.append(stats.t.interval(confidence=0.95, df=c-1, loc=m, scale=s)[1])\n",
    "                ci95_lo.append(stats.t.interval(confidence=0.95, df=c-1, loc=m, scale=s)[0])\n",
    "            df[metric,'ci95_hi'] = ci95_hi\n",
    "            df[metric,'ci95_lo'] = ci95_lo\n",
    "            # df[metric,'ci95']=list(zip(ci95_lo,ci95_hi))\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_MSD(list_of_dfs, by):\n",
    "    new_list_of_dfs = []\n",
    "    \n",
    "    for df in list_of_dfs:\n",
    "        # Get phenotype column name (assuming 2nd column is the metric)\n",
    "        pheno_col = df.columns[1]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = df.groupby(by)[df.columns[1]].agg(['mean', 'count', 'sem'])\n",
    "\n",
    "        \n",
    "        # Convert to MultiIndex if needed (more robust version)\n",
    "        if not isinstance(stats.columns, pd.MultiIndex):\n",
    "            stats.columns = pd.MultiIndex.from_tuples([(pheno_col, col) for col in stats.columns])\n",
    "        \n",
    "        # Calculate CI\n",
    "        stats_2 = ci95(stats)\n",
    "        \n",
    "        # Get N2 control data\n",
    "        if Screen == \"Neuron_Genes_Screen\":\n",
    "            N2_mask = stats_2.index == 'N2' if by == \"Gene\" else stats_2.index.isin(['N2_XJ1','N2_N2'])\n",
    "        else:\n",
    "            N2_mask = stats_2.index == 'N2'\n",
    "            \n",
    "        N2_data = stats_2[N2_mask]\n",
    "        \n",
    "        # Subtract N2 values\n",
    "        stats_2.iloc[:, 0] -= N2_data.iloc[0, 0]  # mean\n",
    "        stats_2.iloc[:, 3] -= N2_data.iloc[0, 0]  # ci95_hi\n",
    "        stats_2.iloc[:, 4] -= N2_data.iloc[0, 0]  # ci95_low\n",
    "        \n",
    "        new_list_of_dfs.append(stats_2)\n",
    "    \n",
    "    return new_list_of_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3396554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSD(list_of_dfs, by):\n",
    "    new_list_of_dfs = []\n",
    "    \n",
    "    for df in list_of_dfs:\n",
    "        # Get phenotype column name (assuming 2nd column is the metric)\n",
    "        pheno_col = df.columns[1]\n",
    "        \n",
    "        # Create proper MultiIndex structure\n",
    "        stats = df.groupby(by)[df.columns[1]].agg(['mean', 'count', 'sem'])\n",
    "\n",
    "        # Convert to MultiIndex if needed (more robust version)\n",
    "        if not isinstance(stats.columns, pd.MultiIndex):\n",
    "            stats.columns = pd.MultiIndex.from_tuples([(pheno_col, col) for col in stats.columns])\n",
    "        \n",
    "        # Calculate CIs\n",
    "        stats_2 = ci95(stats)\n",
    "        \n",
    "        # Get N2 control data\n",
    "        if Screen == \"Neuron_Genes_Screen\":\n",
    "            N2_mask = stats_2.index == 'N2' if by == \"Gene\" else stats_2.index.isin(['N2_XJ1','N2_N2'])\n",
    "        else:\n",
    "            N2_mask = stats_2.index == 'N2'\n",
    "            \n",
    "        N2_data = stats_2[N2_mask]\n",
    "        \n",
    "        # Subtract N2 values\n",
    "        stats_2.iloc[:, 0] -= N2_data.iloc[0, 0]  # mean\n",
    "        stats_2.iloc[:, 3] -= N2_data.iloc[0, 0]  # ci95_hi\n",
    "        stats_2.iloc[:, 4] -= N2_data.iloc[0, 0]  # ci95_low\n",
    "        \n",
    "        new_list_of_dfs.append(stats_2)\n",
    "    \n",
    "    return new_list_of_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c480e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSD(list_MSD):\n",
    "    '''\n",
    "    input: List of dataframes, each representing a phenotype with calculated MSD.\n",
    "\n",
    "    returns: Single combined dataframe joining all input dataframes with MSD values.\n",
    "    '''\n",
    "    for a in list_MSD:\n",
    "        if a.columns.levels[0] == list_MSD[0].columns.levels[0]:\n",
    "            MSD=a\n",
    "        else:\n",
    "            MSD=MSD.join(a)\n",
    "    return MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_MSD(baseline_byplate,tap_byplate, psa_byplate, by=['Gene','dataset']):\n",
    "    \"\"\"\n",
    "    Combines MSD datafram from baseline plates and tap plates\n",
    "\n",
    "    input:\n",
    "        - baseline_byplate: baseline data by plate\n",
    "        - tap_byplate: tap data by plate\n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "    returns:\n",
    "        - combined MSD dataframe\n",
    "    \"\"\"\n",
    "    list_baseline_MSD=calculate_MSD(extract_phenotypes(baseline_byplate), by=by)\n",
    "\n",
    "    list_tap_MSD=calculate_MSD(extract_phenotypes(tap_byplate), by=by)\n",
    "\n",
    "    list_psa_MSD=calculate_MSD(extract_phenotypes(psa_byplate), by=by)\n",
    "\n",
    "    baseline_MSD = get_MSD(list_baseline_MSD)\n",
    "    \n",
    "    tap_MSD = get_MSD(list_tap_MSD)\n",
    "\n",
    "    psa_MSD = get_MSD(list_psa_MSD)\n",
    "\n",
    "    combined_MSD = pd.merge(pd.merge(baseline_MSD, tap_MSD, on=by, how='outer'), psa_MSD, on=by, how='outer')\n",
    "\n",
    "    combined_MSD=combined_MSD.rename(columns={\"habit_dura\":\"Habituation of Response Duration\",\n",
    "                                         \"habit_prob\": \"Habituation of Respones Probability\",\n",
    "                                         \"habit_speed\":\"Habituation of Response Speed\",\n",
    "                                         \"init_dura\": \"Initial Response Duration\",\n",
    "                                         \"init_prob\": \"Initial Response Probability\",\n",
    "                                         \"init_speed\": \"Initial Response Speed\",\n",
    "                                         \"final_dura\": \"Final Response Duration\",\n",
    "                                         \"final_prob\": \"Final Response Probability\",\n",
    "                                         \"final_speed\": \"Final Response Speed\",\n",
    "                                         \"recovery_dura\": \"Spontaneous Recovery of Response Duration\",\n",
    "                                         \"recovery_prob\": \"Spontaneous Recovery of Response Probability\",\n",
    "                                         \"recovery_speed\": \"Spontaneous Recovery of Response Speed\",\n",
    "                                         \"memory_retention_dura\": \"Memory Retention of Response Duration\",\n",
    "                                         \"memory_retention_prob\": \"Memory Retention of Response Probability\",\n",
    "                                         \"memory_retention_speed\": \"Memory Retention of Response Speed\"})\n",
    "\n",
    "    combined_MSD=combined_MSD.reset_index()\n",
    "    combined_MSD.columns = combined_MSD.columns.to_flat_index().str.join('-')\n",
    "    combined_MSD=combined_MSD.rename(columns={by+\"-\": by})\n",
    "    combined_MSD['Screen']=Screen\n",
    "    \n",
    "    return combined_MSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd616c75",
   "metadata": {},
   "source": [
    "### 3.2.1 Gene-level SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e692a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_MSD=get_combined_MSD(baseline_output_byplate,\n",
    "                              tap_data_byplate, \n",
    "                              psa_data_byplate,\n",
    "                              by='Gene')\n",
    "\n",
    "combined_MSD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e39002-cc71-4b7e-8404-6fd5d9eaccef",
   "metadata": {},
   "source": [
    "### 3.2.2 Allele-level SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_combined_MSD=get_combined_MSD(baseline_output_allele_byplate,\n",
    "                                     tap_data_allele_byplate, \n",
    "                                     psa_data_allele_byplate,\n",
    "                                     by='dataset')\n",
    "\n",
    "allele_combined_MSD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634a41e",
   "metadata": {},
   "source": [
    "## 3.3 T-Stat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_metrics(by=[\"Gene\",\"dataset\"]):\n",
    "    \"\"\"\n",
    "    Create a list of empty dataframe and list of metrics for baseline analysis\n",
    "\n",
    "    input:\n",
    "        by (list): what to group by \"Gene\" or \"dataset\"\n",
    "        \n",
    "    returns:\n",
    "        list_baseline_Tstats: dataframes to store t-statistics\n",
    "        list_baseline_metrics: dataframes to store metic names\n",
    "    \"\"\"\n",
    "    PD_baseline_instantspeed_T=pd.DataFrame(columns = [by,\"Instantaneous Speed\"])\n",
    "    PD_baseline_intspeed_T=pd.DataFrame(columns = [by,\"Interval Speed\"])\n",
    "    PD_baseline_bias_T=pd.DataFrame(columns = [by,\"Bias\"])\n",
    "    PD_baseline_morphwidth_T=pd.DataFrame(columns = [by,\"Morphwidth\"])\n",
    "    PD_baseline_midline_T=pd.DataFrame(columns = [by,\"Midline\"])\n",
    "    PD_baseline_area_T=pd.DataFrame(columns = [by,\"Area\"])\n",
    "    PD_baseline_angularspeed_T=pd.DataFrame(columns = [by,\"Angular Speed\"])\n",
    "    PD_baseline_aspectratio_T=pd.DataFrame(columns = [by,\"Aspect Ratio\"])\n",
    "    PD_baseline_kink_T=pd.DataFrame(columns = [by,\"Kink\"])\n",
    "    PD_baseline_curve_T=pd.DataFrame(columns = [by,\"Curve\"])\n",
    "    PD_baseline_crab_T=pd.DataFrame(columns = [by,\"Crab\"])\n",
    "    PD_baseline_pathlength_T=pd.DataFrame(columns = [by,\"Pathlength\"])\n",
    "\n",
    "    list_baseline_Tstats=[PD_baseline_instantspeed_T,\n",
    "                        PD_baseline_intspeed_T,\n",
    "                        PD_baseline_bias_T,\n",
    "                        PD_baseline_morphwidth_T,\n",
    "                        PD_baseline_midline_T,\n",
    "                        PD_baseline_area_T,\n",
    "                        PD_baseline_angularspeed_T,\n",
    "                        PD_baseline_aspectratio_T,\n",
    "                        PD_baseline_kink_T,\n",
    "                        PD_baseline_curve_T,\n",
    "                        PD_baseline_crab_T,\n",
    "                        PD_baseline_pathlength_T]\n",
    "\n",
    "    list_baseline_metrics=[\"Instantaneous Speed\",\n",
    "                        \"Interval Speed\",\n",
    "                        \"Bias\",\n",
    "                        \"Morphwidth\",\n",
    "                        \"Midline\",\n",
    "                        \"Area\",\n",
    "                        \"Angular Speed\",\n",
    "                        \"Aspect Ratio\",\n",
    "                        \"Kink\",\n",
    "                        \"Curve\",\n",
    "                        \"Crab\",\n",
    "                        \"Pathlength\"]\n",
    "    \n",
    "    return list_baseline_Tstats, list_baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tap_metrics(by=[\"Gene\",\"dataset\"]):\n",
    "    \"\"\"\n",
    "    Create a list of empty dataframes and list of metrics for tap analysis\n",
    "\n",
    "    input:\n",
    "        by (list): what to group by \"Gene\" or \"dataset\"\n",
    "        \n",
    "    returns:\n",
    "        list_tap_Tstats: dataframes to store t-statistics\n",
    "        list_tap_metrics: dataframes to store metic names\n",
    "    \"\"\"\n",
    "    recovery_dura=pd.DataFrame(columns = [by,\"Recovery Duration\"])\n",
    "    recovery_prob=pd.DataFrame(columns = [by,\"Recovery Probability\"])\n",
    "    recovery_speed=pd.DataFrame(columns = [by,\"Recovery Speed\"])\n",
    "    memory_retention_dura=pd.DataFrame(columns = [by,\"Memory Retention Duration\"])\n",
    "    memory_retention_prob=pd.DataFrame(columns = [by,\"Memory Retention Probability\"])\n",
    "    memory_retention_speed=pd.DataFrame(columns = [by,\"Memory Retention Speed\"])\n",
    "    init_dura=pd.DataFrame(columns = [by,\"Initial Duration\"])\n",
    "    init_prob=pd.DataFrame(columns = [by,\"Initial Probability\"])\n",
    "    init_speed=pd.DataFrame(columns = [by,\"Initial Speed\"])\n",
    "    final_dura=pd.DataFrame(columns = [by,\"Final Duration\"])\n",
    "    final_prob=pd.DataFrame(columns = [by,\"Final Probability\"])\n",
    "    final_speed=pd.DataFrame(columns = [by,\"Final Speed\"])\n",
    "    hab_dura=pd.DataFrame(columns = [by,\"Habituation of Duration\"])\n",
    "    hab_prob=pd.DataFrame(columns = [by,\"Habituation of Probability\"])\n",
    "    hab_speed=pd.DataFrame(columns = [by,\"Habituation of Speed\"])\n",
    "\n",
    "    list_tap_Tstats = [recovery_dura,\n",
    "                    recovery_prob,\n",
    "                    recovery_speed,\n",
    "                    memory_retention_dura,\n",
    "                    memory_retention_prob,\n",
    "                    memory_retention_speed,\n",
    "                    init_dura,\n",
    "                    init_prob,\n",
    "                    init_speed,\n",
    "                    final_dura,\n",
    "                    final_prob,\n",
    "                    final_speed,\n",
    "                    hab_dura,\n",
    "                    hab_prob,\n",
    "                    hab_speed]\n",
    "    \n",
    "    list_tap_metrics = [\"recovery_dura\",\n",
    "                        \"recovery_prob\",\n",
    "                        \"recovery_speed\",\n",
    "                        \"memory_retention_dura\",\n",
    "                        \"memory_retention_prob\",\n",
    "                        \"memory_retention_speed\",\n",
    "                        \"init_dura\",\n",
    "                        \"init_prob\",\n",
    "                        \"init_speed\",\n",
    "                        \"final_dura\",\n",
    "                        \"final_prob\",\n",
    "                        \"final_speed\",\n",
    "                        \"habit_dura\",\n",
    "                        \"habit_prob\",\n",
    "                        \"habit_speed\"]\n",
    "    \n",
    "    return list_tap_Tstats, list_tap_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psa_metrics(by=[\"Gene\", \"dataset\"]):\n",
    "    \"\"\"\n",
    "    Create a list of empty dataframes and list of metric names for PSA summary analysis.\n",
    "\n",
    "    input:\n",
    "        by (list): what to group by (\"Gene\" or \"dataset\")\n",
    "\n",
    "    returns:\n",
    "        list_psa_Tstats: list of empty DataFrames for t-statistics\n",
    "        list_psa_metrics: list of metric names (short strings)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    psa_initial_speed = pd.DataFrame(columns=[by,\"Initial PSA Instantaneous Speed\"])\n",
    "    psa_final_speed = pd.DataFrame(columns=[by,\"Final PSA Instantaneous Speed\"])\n",
    "    psa_recovery_speed = pd.DataFrame(columns=[by,\"Recovery PSA Instantaneous Speed\"])\n",
    "    psa_peak_speed = pd.DataFrame(columns=[by,\"Peak PSA Instantaneous Speed\"])\n",
    "    psa_peak_tap_speed = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Instantaneous Speed\"])\n",
    "    psa_avg_speed = pd.DataFrame(columns=[by,\"Average PSA Instantaneous Speed\"])\n",
    "    psa_sensitization_speed = pd.DataFrame(columns=[by,\"Sensitization PSA Instantaneous Speed\"])\n",
    "    psa_habituation_speed = pd.DataFrame(columns=[by,\"Habituation PSA Instantaneous Speed\"])\n",
    "    psa_spontaneous_recovery_speed = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Instantaneous Speed\"])\n",
    "    psa_memory_retention_speed = pd.DataFrame(columns=[by,\"Memory Retention PSA Instantaneous Speed\"])\n",
    "    # psa_initial_to_peak_speed = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Instantaneous Speed\"])\n",
    "    # psa_peak_to_recovery_speed = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Instantaneous Speed\"])\n",
    "\n",
    "    psa_initial_bias = pd.DataFrame(columns=[by,\"Initial PSA Bias\"])\n",
    "    psa_final_bias = pd.DataFrame(columns=[by,\"Final PSA Bias\"])\n",
    "    psa_recovery_bias = pd.DataFrame(columns=[by,\"Recovery PSA Bias\"])\n",
    "    psa_peak_bias = pd.DataFrame(columns=[by,\"Peak PSA Bias\"])\n",
    "    psa_peak_tap_bias = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Bias\"])\n",
    "    psa_avg_bias = pd.DataFrame(columns=[by,\"Average PSA Bias\"])\n",
    "    psa_sensitization_bias = pd.DataFrame(columns=[by,\"Sensitization PSA Bias\"])\n",
    "    psa_habituation_bias = pd.DataFrame(columns=[by,\"Habituation PSA Bias\"])\n",
    "    psa_spontaneous_recovery_bias = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Bias\"])\n",
    "    psa_memory_retention_bias = pd.DataFrame(columns=[by,\"Memory Retention PSA Bias\"])\n",
    "    # psa_initial_to_peak_bias = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Bias\"])\n",
    "    # psa_peak_to_recovery_bias = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Bias\"])\n",
    "\n",
    "    psa_initial_ang_speed = pd.DataFrame(columns=[by,\"Initial PSA Angular Speed\"])\n",
    "    psa_final_ang_speed = pd.DataFrame(columns=[by,\"Final PSA Angular Speed\"])\n",
    "    psa_recovery_ang_speed = pd.DataFrame(columns=[by,\"Recovery PSA Angular Speed\"])\n",
    "    psa_peak_ang_speed = pd.DataFrame(columns=[by,\"Peak PSA Angular Speed\"])\n",
    "    psa_peak_tap_ang_speed = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Angular Speed\"])\n",
    "    psa_avg_ang_speed = pd.DataFrame(columns=[by,\"Average PSA Angular Speed\"])\n",
    "    psa_sensitization_ang_speed = pd.DataFrame(columns=[by,\"Sensitization PSA Angular Speed\"])\n",
    "    psa_habituation_ang_speed = pd.DataFrame(columns=[by,\"Habituation PSA Angular Speed\"])\n",
    "    psa_spontaneous_recovery_ang_speed = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Angular Speed\"])\n",
    "    psa_memory_retention_ang_speed = pd.DataFrame(columns=[by,\"Memory Retention PSA Angular Speed\"])\n",
    "    # psa_initial_to_peak_ang_speed = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Angular Speed\"])\n",
    "    # psa_peak_to_recovery_ang_speed = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Angular Speed\"])\n",
    "\n",
    "    psa_initial_aspect = pd.DataFrame(columns=[by,\"Initial PSA Aspect Ratio\"])\n",
    "    psa_final_aspect = pd.DataFrame(columns=[by,\"Final PSA Aspect Ratio\"])\n",
    "    psa_recovery_aspect = pd.DataFrame(columns=[by,\"Recovery PSA Aspect Ratio\"])\n",
    "    psa_peak_aspect = pd.DataFrame(columns=[by,\"Peak PSA Aspect Ratio\"])\n",
    "    psa_peak_tap_aspect = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Aspect Ratio\"])\n",
    "    psa_avg_aspect = pd.DataFrame(columns=[by,\"Average PSA Aspect Ratio\"])\n",
    "    psa_sensitization_aspect = pd.DataFrame(columns=[by,\"Sensitization PSA Aspect Ratio\"])\n",
    "    psa_habituation_aspect = pd.DataFrame(columns=[by,\"Habituation PSA Aspect Ratio\"])\n",
    "    psa_spontaneous_recovery_aspect = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Aspect Ratio\"])\n",
    "    psa_memory_retention_aspect = pd.DataFrame(columns=[by,\"Memory Retention PSA Aspect Ratio\"])\n",
    "    # psa_initial_to_peak_aspect = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Aspect Ratio\"])\n",
    "    # psa_peak_to_recovery_aspect = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Aspect Ratio\"])\n",
    "\n",
    "    psa_initial_kink = pd.DataFrame(columns=[by,\"Initial PSA Kink\"])\n",
    "    psa_final_kink = pd.DataFrame(columns=[by,\"Final PSA Kink\"])\n",
    "    psa_recovery_kink = pd.DataFrame(columns=[by,\"Recovery PSA Kink\"])\n",
    "    psa_peak_kink = pd.DataFrame(columns=[by,\"Peak PSA Kink\"])\n",
    "    psa_peak_tap_kink = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Kink\"])\n",
    "    psa_avg_kink = pd.DataFrame(columns=[by,\"Average PSA Kink\"])\n",
    "    psa_sensitization_kink = pd.DataFrame(columns=[by,\"Sensitization PSA Kink\"])\n",
    "    psa_habituation_kink = pd.DataFrame(columns=[by,\"Habituation PSA Kink\"])\n",
    "    psa_spontaneous_recovery_kink = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Kink\"])\n",
    "    psa_memory_retention_kink = pd.DataFrame(columns=[by,\"Memory Retention PSA Kink\"])\n",
    "    # psa_initial_to_peak_kink = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Kink\"])\n",
    "    # psa_peak_to_recovery_kink = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Kink\"])\n",
    "\n",
    "    psa_initial_curve = pd.DataFrame(columns=[by,\"Initial PSA Curve\"])\n",
    "    psa_final_curve = pd.DataFrame(columns=[by,\"Final PSA Curve\"])\n",
    "    psa_recovery_curve = pd.DataFrame(columns=[by,\"Recovery PSA Curve\"])\n",
    "    psa_peak_curve = pd.DataFrame(columns=[by,\"Peak PSA Curve\"])\n",
    "    psa_peak_tap_curve = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Curve\"])\n",
    "    psa_avg_curve = pd.DataFrame(columns=[by,\"Average PSA Curve\"])\n",
    "    psa_sensitization_curve = pd.DataFrame(columns=[by,\"Sensitization PSA Curve\"])\n",
    "    psa_habituation_curve = pd.DataFrame(columns=[by,\"Habituation PSA Curve\"])\n",
    "    psa_spontaneous_recovery_curve = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Curve\"])\n",
    "    psa_memory_retention_curve = pd.DataFrame(columns=[by,\"Memory Retention PSA Curve\"])\n",
    "    # psa_initial_to_peak_curve = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Curve\"])\n",
    "    # psa_peak_to_recovery_curve = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Curve\"])\n",
    "\n",
    "    psa_initial_crab = pd.DataFrame(columns=[by,\"Initial PSA Crab\"])\n",
    "    psa_final_crab = pd.DataFrame(columns=[by,\"Final PSA Crab\"])\n",
    "    psa_recovery_crab = pd.DataFrame(columns=[by,\"Recovery PSA Crab\"])\n",
    "    psa_peak_crab = pd.DataFrame(columns=[by,\"Peak PSA Crab\"])\n",
    "    psa_peak_tap_crab = pd.DataFrame(columns=[by,\"Peak Tap Number PSA Crab\"])\n",
    "    psa_avg_crab = pd.DataFrame(columns=[by,\"Average PSA Crab\"])\n",
    "    psa_sensitization_crab = pd.DataFrame(columns=[by,\"Sensitization PSA Crab\"])\n",
    "    psa_habituation_crab = pd.DataFrame(columns=[by,\"Habituation PSA Crab\"])\n",
    "    psa_spontaneous_recovery_crab = pd.DataFrame(columns=[by,\"Spontaneous Recovery PSA Crab\"])\n",
    "    psa_memory_retention_crab = pd.DataFrame(columns=[by,\"Memory Retention PSA Crab\"])\n",
    "    # psa_initial_to_peak_crab = pd.DataFrame(columns=[by,\"Initial_to_peak PSA Crab\"])\n",
    "    # psa_peak_to_recovery_crab = pd.DataFrame(columns=[by,\"Peak_to_recovery PSA Crab\"])\n",
    "\n",
    "    list_psa_Tstats = [\n",
    "        psa_initial_speed, psa_final_speed,psa_recovery_speed, psa_peak_speed, psa_peak_tap_speed, psa_avg_speed,\n",
    "        psa_sensitization_speed, psa_habituation_speed, psa_spontaneous_recovery_speed, psa_memory_retention_speed,\n",
    "\n",
    "\n",
    "        psa_initial_bias, psa_final_bias, psa_recovery_bias, psa_peak_bias, psa_peak_tap_bias, psa_avg_bias,\n",
    "        psa_sensitization_bias, psa_habituation_bias, psa_spontaneous_recovery_bias, psa_memory_retention_bias,\n",
    "\n",
    "        psa_initial_ang_speed, psa_final_ang_speed, psa_recovery_ang_speed, psa_peak_ang_speed, psa_peak_tap_ang_speed, psa_avg_ang_speed,\n",
    "        psa_sensitization_ang_speed, psa_habituation_ang_speed, psa_spontaneous_recovery_ang_speed, psa_memory_retention_ang_speed,\n",
    "\n",
    "        psa_initial_aspect, psa_final_aspect, psa_recovery_aspect, psa_peak_aspect, psa_peak_tap_aspect, psa_avg_aspect,\n",
    "        psa_sensitization_aspect, psa_habituation_aspect, psa_spontaneous_recovery_aspect, psa_memory_retention_aspect,\n",
    "\n",
    "        psa_initial_kink, psa_final_kink, psa_recovery_kink, psa_peak_kink, psa_peak_tap_kink, psa_avg_kink,\n",
    "        psa_sensitization_kink, psa_habituation_kink, psa_spontaneous_recovery_kink, psa_memory_retention_kink,\n",
    "\n",
    "        psa_initial_curve, psa_final_curve, psa_recovery_curve, psa_peak_curve, psa_peak_tap_curve, psa_avg_curve,\n",
    "        psa_sensitization_curve, psa_habituation_curve, psa_spontaneous_recovery_curve, psa_memory_retention_curve,\n",
    "\n",
    "        psa_initial_crab, psa_final_crab, psa_recovery_crab, psa_peak_crab, psa_peak_tap_crab, psa_avg_crab,\n",
    "        psa_sensitization_crab, psa_habituation_crab, psa_spontaneous_recovery_crab, psa_memory_retention_crab\n",
    "    ]\n",
    "\n",
    "    list_psa_metrics = [\n",
    "    \"Initial PSA Instantaneous Speed\",\n",
    "    \"Final PSA Instantaneous Speed\",\n",
    "    \"Recovery PSA Instantaneous Speed\",\n",
    "    \"Peak PSA Instantaneous Speed\",\n",
    "    \"Peak Tap Number PSA Instantaneous Speed\",\n",
    "    \"Average PSA Instantaneous Speed\",\n",
    "    \"Sensitization PSA Instantaneous Speed\",\n",
    "    \"Habituation PSA Instantaneous Speed\",\n",
    "    \"Spontaneous Recovery PSA Instantaneous Speed\",\n",
    "    \"Memory Retention PSA Instantaneous Speed\",\n",
    "\n",
    "    \"Initial PSA Bias\",\n",
    "    \"Final PSA Bias\",\n",
    "    \"Recovery PSA Bias\",\n",
    "    \"Peak PSA Bias\",\n",
    "    \"Peak Tap Number PSA Bias\",\n",
    "    \"Average PSA Bias\",\n",
    "    \"Sensitization PSA Bias\",\n",
    "    \"Habituation PSA Bias\",\n",
    "    \"Spontaneous Recovery PSA Bias\",\n",
    "    \"Memory Retention PSA Bias\",\n",
    "\n",
    "    \"Initial PSA Angular Speed\",\n",
    "    \"Final PSA Angular Speed\",\n",
    "    \"Recovery PSA Angular Speed\",\n",
    "    \"Peak PSA Angular Speed\",\n",
    "    \"Peak Tap Number PSA Angular Speed\",\n",
    "    \"Average PSA Angular Speed\",\n",
    "    \"Sensitization PSA Angular Speed\",\n",
    "    \"Habituation PSA Angular Speed\",\n",
    "    \"Spontaneous Recovery PSA Angular Speed\",\n",
    "    \"Memory Retention PSA Angular Speed\",\n",
    "\n",
    "    \"Initial PSA Aspect Ratio\",\n",
    "    \"Final PSA Aspect Ratio\",\n",
    "    \"Recovery PSA Aspect Ratio\",\n",
    "    \"Peak PSA Aspect Ratio\",\n",
    "    \"Peak Tap Number PSA Aspect Ratio\",\n",
    "    \"Average PSA Aspect Ratio\",\n",
    "    \"Sensitization PSA Aspect Ratio\",\n",
    "    \"Habituation PSA Aspect Ratio\",\n",
    "    \"Spontaneous Recovery PSA Aspect Ratio\",\n",
    "    \"Memory Retention PSA Aspect Ratio\",\n",
    "\n",
    "\n",
    "    \"Initial PSA Kink\",\n",
    "    \"Final PSA Kink\",\n",
    "    \"Recovery PSA Kink\",\n",
    "    \"Peak PSA Kink\",\n",
    "    \"Peak Tap Number PSA Kink\",\n",
    "    \"Average PSA Kink\",\n",
    "    \"Sensitization PSA Kink\",\n",
    "    \"Habituation PSA Kink\",\n",
    "    \"Spontaneous Recovery PSA Kink\",\n",
    "    \"Memory Retention PSA Kink\",\n",
    "\n",
    "    \"Initial PSA Curve\",\n",
    "    \"Final PSA Curve\",\n",
    "    \"Recovery PSA Curve\",\n",
    "    \"Peak PSA Curve\",\n",
    "    \"Peak Tap Number PSA Curve\",\n",
    "    \"Average PSA Curve\",\n",
    "    \"Sensitization PSA Curve\",\n",
    "    \"Habituation PSA Curve\",\n",
    "    \"Spontaneous Recovery PSA Curve\",\n",
    "    \"Memory Retention PSA Curve\",\n",
    "\n",
    "    \"Initial PSA Crab\",\n",
    "    \"Final PSA Crab\",\n",
    "    \"Recovery PSA Crab\",\n",
    "    \"Peak PSA Crab\",\n",
    "    \"Peak Tap Number PSA Crab\",\n",
    "    \"Average PSA Crab\",\n",
    "    \"Sensitization PSA Crab\",\n",
    "    \"Habituation PSA Crab\",\n",
    "    \"Spontaneous Recovery PSA Crab\",\n",
    "    \"Memory Retention PSA Crab\"\n",
    "]\n",
    "    \n",
    "    return list_psa_Tstats, list_psa_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62abf35-b324-4b96-9328-91df56e05470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTest(Type, DF_ref, output, by=[\"Gene\", \"dataset\"]):\n",
    "    \"\"\"\n",
    "    Perform two sample t-test for each unique Gene/dataset column in the Df_ref\n",
    "    input: \n",
    "        - a:column name of values \n",
    "        - DF_ref:reference dataframe\n",
    "        - output: output df to store results in \n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "        \n",
    "    \"\"\"\n",
    "    for a in DF_ref[by].unique():\n",
    "        Tstat_a = ttest_ind(DF_ref[DF_ref.dataset == a][Type], DF_ref[DF_ref.Allele.isin([\"XJ1\",\"N2\"])][Type],equal_var=False)[0]\n",
    "        Tstat_g = ttest_ind(DF_ref[DF_ref.Gene == a][Type], DF_ref[DF_ref.Gene == \"N2\"][Type],equal_var=False)[0]\n",
    "        Tstat = Tstat_g if by==\"Gene\" else Tstat_a\n",
    "        row = [a, Tstat]\n",
    "        output.loc[len(output)] = row\n",
    "    # print(output)\n",
    "\n",
    "def do_TTest(by=[\"Gene\", \"dataset\"], baseline=[\"true\", \"false\", \"psa\"]):\n",
    "    \"\"\"\n",
    "    Perform TTest function for each unique Gene/dataset column in baseline_output/tap_data\n",
    "    \n",
    "    input: \n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "        - baseline: whether or not to use baseline data\n",
    "\n",
    "    returns: sorted T-statistics dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    if baseline==\"true\":\n",
    "        list_Tstats, list_metrics = baseline_metrics(by)\n",
    "        data = baseline_output\n",
    "    elif baseline==\"false\":\n",
    "        list_Tstats,list_metrics = tap_metrics(by)\n",
    "        data = tap_data\n",
    "    else:\n",
    "        list_Tstats,list_metrics = psa_metrics(by)\n",
    "        data = psa_data\n",
    "    for x in data[by].unique():\n",
    "        if Screen==\"Neuron_Genes_Screen\":\n",
    "            condition = x in ([\"N2\"] if by == \"Gene\" else [\"N2_XJ1\", \"N2_N2\"])\n",
    "        else:\n",
    "            condition = (x ==\"N2\")\n",
    "        if condition:\n",
    "            pass\n",
    "        else:\n",
    "            output_gene=data[data[by]==x]\n",
    "            gene_data=data[data['Date'].isin(output_gene['Date'].unique())]\n",
    "            if Screen==\"Neuron_Genes_Screen\":\n",
    "                gene_data_final = gene_data[gene_data[by].isin(['N2', x])] if by==\"Gene\" else gene_data[gene_data[by].isin(['N2_N2','N2_XJ1', x])]\n",
    "            else:\n",
    "                gene_data_final = gene_data[gene_data[by].isin(['N2', x])]\n",
    "\n",
    "            for a,b in zip(list_metrics, list_Tstats):\n",
    "                TTest(a, gene_data_final, b, by) # calls t test function\n",
    "    \n",
    "    PD_Tstats=pd.DataFrame()\n",
    "    for a in list_Tstats:\n",
    "        b=a.groupby([by], as_index=False).mean()\n",
    "        if b.columns.values[1] == list_Tstats[0].columns.values[1]:\n",
    "            PD_Tstats=b\n",
    "        else:\n",
    "            PD_Tstats=PD_Tstats.join(b.iloc[:,1])\n",
    "            \n",
    "    PD_Tstats=PD_Tstats.set_index(by)\n",
    "    \n",
    "    return PD_Tstats\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7965278",
   "metadata": {},
   "source": [
    "### T-stat on Baseline data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5784896-b993-4ecb-9ae9-c168d7469d90",
   "metadata": {},
   "source": [
    "### 3.3.1 Allele-level T-stat analysis of baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc477df9-91aa-41d6-a527-c61d20f99fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_baseline_Tstats_allele = do_TTest(\"dataset\", baseline=\"true\") # get sorted T-statistics DataFrame \n",
    "\n",
    "# PD_baseline_Tstats_allele_sorted=PD_baseline_Tstats_allele.sort_index()\n",
    "\n",
    "PD_baseline_Tstats_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6e5cc-a2b0-4fd8-9bc4-668b1cc22d5e",
   "metadata": {},
   "source": [
    "### 3.3.2 Gene-level T-stat analysis of baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ea9e3-1121-4b1c-ac15-77bcef16cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_baseline_Tstats=do_TTest(\"Gene\", baseline=\"true\") # get sorted T-statistics DataFrame \n",
    "\n",
    "# PD_baseline_Tstats_sorted=PD_baseline_Tstats.sort_index()\n",
    "\n",
    "PD_baseline_Tstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80323af7-e75f-4678-b5dd-810a7607fc83",
   "metadata": {},
   "source": [
    "### T-stat analysis for tap-response data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c679a-166c-43d0-946e-226ee9a20c1d",
   "metadata": {},
   "source": [
    "### 3.3.3 Allele level T-stat analysis of tap response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4585676",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_habituation_Tstats_allele = do_TTest(\"dataset\", baseline=\"false\") # get sorted T-statistics DataFrame \n",
    "\n",
    "# PD_habituation_Tstats_allele_sorted=PD_habituation_Tstats_allele.sort_index()\n",
    "\n",
    "PD_habituation_Tstats_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f44a6d-6632-4e0f-8c58-a7060daf756d",
   "metadata": {},
   "source": [
    "### 3.3.4 Gene-level T-stat analysis of Tap response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bb7d2-d1e7-4227-a056-0ca0e1d10c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_habituation_Tstats = do_TTest(\"Gene\", baseline=\"false\") # get sorted T-statistics DataFrame \n",
    "\n",
    "PD_habituation_Tstats_sorted=PD_habituation_Tstats.sort_index()\n",
    "\n",
    "PD_habituation_Tstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563292bd",
   "metadata": {},
   "source": [
    "### T-stat analysis for psa data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7a2fa",
   "metadata": {},
   "source": [
    "### 3.3.5 Allele level T-stat analysis of PSA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "psa_tstats_allele = do_TTest(\"dataset\", baseline=\"psa\") # get sorted T-statistics DataFrame \n",
    "\n",
    "psa_tstats_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3d77b",
   "metadata": {},
   "source": [
    "### 3.3.6 Gene-level T-stat analysis of PSA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "psa_tstats = do_TTest(\"Gene\", baseline=\"psa\") # get sorted T-statistics DataFrame \n",
    "\n",
    "psa_tstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3071bf3-afd5-49e8-baa4-7e37dd120383",
   "metadata": {},
   "source": [
    "# 4. Merging t-stat data into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16271ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_cols(combined):\n",
    "    \"\"\"\n",
    "    Reorders columns in the combined dataframe. \n",
    "    (pops specific columns[\"Area\", \"Midline\", \"Morphwidth\", \"Angular Speed\"] and\n",
    "    reinserts at different positions)\n",
    "\n",
    "    input:\n",
    "        combined: dataframe with columns to be reordered\n",
    "\n",
    "    returns: \n",
    "        NA    \n",
    "        \n",
    "    \"\"\"\n",
    "    first_col=combined.pop(\"Area\")\n",
    "    combined.insert(0,\"Area\",first_col)\n",
    "\n",
    "    first_col=combined.pop(\"Midline\")\n",
    "    combined.insert(0,\"Midline\",first_col)\n",
    "\n",
    "    first_col=combined.pop(\"Morphwidth\")\n",
    "    combined.insert(0,\"Morphwidth\",first_col)\n",
    "\n",
    "    first_col=combined.pop(\"Angular Speed\")\n",
    "    combined.insert(5,\"Angular Speed\",first_col)\n",
    "\n",
    "def pop_last(combined):\n",
    "    \"\"\"\n",
    "    Reorders the last three columns of the combined dataframe.\n",
    "    input:\n",
    "        combined: dataframe with columns to be reordered\n",
    "\n",
    "    \"\"\"\n",
    "    last_col=combined.pop(\"Spontaneous Recovery of Response Duration\")\n",
    "    combined.insert(26,\"Spontaneous Recovery of Response Duration\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Spontaneous Recovery of Response Probability\")\n",
    "    combined.insert(26,\"Spontaneous Recovery of Response Probability\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Spontaneous Recovery of Response Speed\")\n",
    "    combined.insert(26,\"Spontaneous Recovery of Response Speed\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Memory Retention of Response Duration\")\n",
    "    combined.insert(26,\"Memory Retention of Response Duration\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Memory Retention of Response Probability\")\n",
    "    combined.insert(26,\"Memory Retention of Response Probability\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Memory Retention of Response Speed\")\n",
    "    combined.insert(26,\"Memory Retention of Response Speed\",last_col)\n",
    "\n",
    "def rename_columns(df):\n",
    "    '''\n",
    "    Renames columns in the input dataframe\n",
    "    input:\n",
    "        combined: dataframe with columns to be renamed   \n",
    "    returns:\n",
    "        input dataframe with renamed columns \n",
    "    '''\n",
    "    renames = {\n",
    "        \"Habituation of Duration\": \"Habituation of Response Duration\",\n",
    "        \"Habituation of Probability\": \"Habituation of Respones Probability\",\n",
    "        \"Habituation of Speed\": \"Habituation of Response Speed\",\n",
    "        \"Initial Duration\": \"Initial Response Duration\",\n",
    "        \"Initial Probability\": \"Initial Response Probability\",\n",
    "        \"Initial Speed\": \"Initial Response Speed\",\n",
    "        \"Final Duration\": \"Final Response Duration\",\n",
    "        \"Final Probability\": \"Final Response Probability\",\n",
    "        \"Final Speed\": \"Final Response Speed\",\n",
    "        \"Recovery Duration\": \"Spontaneous Recovery of Response Duration\",\n",
    "        \"Recovery Probability\": \"Spontaneous Recovery of Response Probability\",\n",
    "        \"Recovery Speed\": \"Spontaneous Recovery of Response Speed\",\n",
    "        \"Memory Retention Duration\": \"Memory Retention of Response Duration\",\n",
    "        \"Memory Retention Probability\": \"Memory Retention of Response Probability\",\n",
    "        \"Memory Retention Speed\": \"Memory Retention of Response Speed\"\n",
    "    }\n",
    "    return df.rename(columns=renames)\n",
    "\n",
    "def merge_Tstats(baseline, habituation, by=[\"Gene\", \"dataset\"], Screen=Screen, psa=False):\n",
    "    \"\"\"\n",
    "    merge baseline and tap response dataframes based on the Gene/dataset\n",
    "    normalize the merged dataframe and then return it with melted version\n",
    "\n",
    "    input:\n",
    "        - baseline: baseline dataframe to merge\n",
    "        - habituation: habituation dataframe to merge\n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "    \"\"\"\n",
    "\n",
    "    #merge baseline and habituation data\n",
    "    combined_Tstats = pd.merge(baseline, habituation, on=by, how='left')\n",
    "    combined_Tstats = combined_Tstats.sort_index() # sort by index\n",
    "\n",
    "    # ------------ NORMALISATION STEPS MOVED TO DASHBOARD -------------------\n",
    "    # # normalise combined dataframe by subtracting mean and div by sd\n",
    "    # combined_Tstats_normalized = (combined_Tstats-combined_Tstats.mean())/combined_Tstats.std()\n",
    "\n",
    "    # if by==\"dataset\" and Screen==\"Neuron_Genes_Screen\":\n",
    "    #     combined_Tstats_normalized_2 = combined_Tstats-combined_Tstats[combined_Tstats.index==\"N2_XJ1\"].squeeze()\n",
    "    # else :\n",
    "    #     combined_Tstats_normalized_2 = combined_Tstats-combined_Tstats[combined_Tstats.index==\"N2\"].squeeze()  \n",
    "\n",
    "    pop_cols(combined_Tstats) # reorder columns\n",
    "\n",
    "    # Skip this step if data = psa\n",
    "    if not psa:\n",
    "        #rename columns of combined and normalized df\n",
    "        combined_Tstats = rename_columns(combined_Tstats)\n",
    "        # combined_Tstats_normalized_2=rename_columns(combined_Tstats_normalized_2)\n",
    "        pop_cols(combined_Tstats) # reorder columns\n",
    "        pop_last(combined_Tstats) # reorder columns\n",
    "\n",
    "    # -------------- PIVOTING STEPS MOVED TO DASHBOARD ---------------------\n",
    "    # # Melt the combined dataframe\n",
    "    # combined_Tstats_melted=combined_Tstats.reset_index()\n",
    "    # combined_Tstats_melted=pd.melt(combined_Tstats_melted, id_vars=[by],\n",
    "    #                             var_name='Metric',\n",
    "    #                             value_name='T_score')\n",
    "    \n",
    "    # # Sort the melted dataframe by T_score\n",
    "    # combined_Tstats_melted_sorted=combined_Tstats_melted.sort_values(by=['T_score'])\n",
    "\n",
    "    # # Melt the normalized dataframe\n",
    "    # combined_Tstats_normalized_melted=combined_Tstats.reset_index()\n",
    "    # combined_Tstats_normalized_melted=pd.melt(combined_Tstats_normalized_melted, id_vars=[by],\n",
    "    #                                                var_name='Metric',\n",
    "    #                                                value_name='T_score')\n",
    "\n",
    "    # add Screen column to df and its melted version\n",
    "    combined_Tstats['Screen']=Screen\n",
    "    # combined_Tstats_normalized_melted['Screen']=Screen\n",
    "\n",
    "    return combined_Tstats#, combined_Tstats_normalized_melted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c436e-1fd2-4bd1-8dd4-53517d4d0f4a",
   "metadata": {},
   "source": [
    "## 4.1 Gene-level\n",
    "\n",
    "- Pass Tap and baseline through merge_Tstats() as df1\n",
    "- Pass PSA and baseline through merge_Tstats()as df2\n",
    "- pd.merge df1 and df2 using all columns of baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eacd88-edb5-4e98-9f49-2d4508cf40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline + Tap\n",
    "combined_Tstats = merge_Tstats(PD_baseline_Tstats, PD_habituation_Tstats, \"Gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline + PSA \n",
    "combined_Tstats_psa = merge_Tstats(\n",
    "    PD_baseline_Tstats, psa_tstats, by=\"Gene\", psa=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce21c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline + Tap + PSA\n",
    "final_tstat = pd.merge(combined_Tstats.reset_index(), combined_Tstats_psa.reset_index(), on = PD_baseline_Tstats.columns.to_list().append(['Gene','Screen']), how = 'inner')\n",
    "\n",
    "final_tstat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9330abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline + Tap + PSA melted\n",
    "# final_tstat_melted = pd.concat([combined_Tstats_normalized_melted, combined_Tstats_psa_melted]).drop_duplicates()\n",
    "\n",
    "# final_tstat_melted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da0e1e-d702-408f-b278-2a05b39ba999",
   "metadata": {},
   "source": [
    "## 4.2 Allele level \n",
    "\n",
    "\n",
    "- Pass Tap and baseline through merge_Tstats() as df3\n",
    "- Pass PSA and baseline through merge_Tstats()as df4\n",
    "- pd.merge df3 and df4 using all columns of basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16521a12-8c86-4310-9455-09054ed08b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline + Tap\n",
    "combined_Tstats_allele = merge_Tstats(PD_baseline_Tstats_allele,PD_habituation_Tstats_allele, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline + PSA \n",
    "combined_Tstats_psa_allele = merge_Tstats(\n",
    "    PD_baseline_Tstats_allele, psa_tstats_allele, by=\"dataset\", psa=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77706c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline + Tap + PSA\n",
    "final_tstat_allele = pd.merge(combined_Tstats_allele.reset_index(), combined_Tstats_psa_allele.reset_index(), on = PD_baseline_Tstats_allele.columns.to_list().append(['dataset','Screen']), how = 'outer')\n",
    "\n",
    "final_tstat_allele.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6185ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tstat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline + Tap + PSA melted\n",
    "# final_tstat_melted_allele = pd.concat([combined_Tstats_normalized_melted_allele, combined_Tstats_psa_melted_allele]).drop_duplicates()\n",
    "\n",
    "# final_tstat_melted_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4915fd6-beba-45a7-9575-346dfe679285",
   "metadata": {},
   "source": [
    "# 5. Save data to database (sqlite3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a06cb-457b-4d9e-bb11-6e6042b6b65b",
   "metadata": {},
   "source": [
    "#### A janky way to add data and update the sql \n",
    "\n",
    "1. Read table to pd.DataFrame\n",
    "2. Add new data to pd.DataFrame\n",
    "3. Replace old table with newly updated pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb60361-29ff-45d7-8d74-0e8f3aed8ac4",
   "metadata": {},
   "source": [
    "# Primary Keys For Each SQL Table:\n",
    "\n",
    "####  -- Gene_Allele_WormBaseID:\n",
    "WBGene, WBAllele\n",
    "#### -- alleleMSD:\n",
    "dataset, Screen\n",
    "#### -- gene_MSD:\n",
    "Gene, Screen\n",
    "#### -- allele_profile_data:\n",
    "dataset, Metric, Screen\n",
    "#### -- gene_profile_data:\n",
    "Gene, Metric, Screen\n",
    "#### -- tap_baseline_data:\n",
    "Time, Plate_id, Date, Screen, dataset\n",
    "#### -- tap_response_data:\n",
    "plate, Date, Plate_id, Screen, taps, dataset, Gene, Allele\n",
    "#### -- tstat_allele_data:\n",
    "dataset, Screen\n",
    "#### -- tstat_gene_data:\n",
    "Gene, Screen\n",
    "#### -- psa_summarized_data:\n",
    "Plate_id,Date,Scree,dataset,Gene,Allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e074b1-35ee-48d0-9656-f401bee9560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tap_output.head(5))\n",
    "# print(baseline_output.head(5))\n",
    "\n",
    "tap_output.Screen = Screen\n",
    "tap_psa_output.Screen = Screen\n",
    "baseline_output.Screen = Screen\n",
    "\n",
    "# print(tap_output.head(5))\n",
    "# print(baseline_output.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tstat_allele[final_tstat_allele.isna().any(axis=1)]\n",
    "final_tstat_allele[final_tstat_allele[\"Morphwidth\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tstat_allele[final_tstat_allele['dataset'] == \"unknown_CZ11000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbda4f1-3d27-4dfe-a6bd-585b64f0d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### This code will connect to PostgreSQL database and write non-duplicate data into the database tables.\n",
    "\n",
    "# Loads database config values from database.ini file and validates that user and password are set.\n",
    "config = load_config()\n",
    "if (config['user'] == \"\" or config['password'] == \"\"):\n",
    "    print(\"Please set your user and password in the database.ini file.\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Creates a connection pool to PostgreSQL database using SQLAlchemy.\n",
    "engine = create_engine(f\"postgresql+psycopg://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\")\n",
    "\n",
    "# Function to insert data into PostgreSQL table, skipping duplicates based on primary keys.\n",
    "def postgres_skip_on_duplicate(pd_table, conn, keys, data_iter):\n",
    "    data = [dict(zip(keys,row)) for row in data_iter]\n",
    "    conn.execute(insert(pd_table.table).on_conflict_do_nothing(), data)\n",
    "\n",
    "# --------- Write the dataframes to PostgreSQL tables -----------\n",
    "\n",
    "# Complete tap response data\n",
    "print(\"working on tap_psa_output:\") \n",
    "tap_psa_output.to_sql('tap_response_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# tap_psa_output.to_sql('tap_response_data', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# Complete baseline data  >NO\n",
    "print(\"working on tap_baseline_data:\") \n",
    "baseline_output.to_sql('tap_baseline_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# baseline_output.to_sql('tap_baseline_data', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# Baseline + Tap + PSA combined tstat data by Gene\n",
    "print(\"working on tstat_gene_data\")\n",
    "final_tstat.dropna(thresh=10).reset_index().to_sql('tstat_gene_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# final_tstat.reset_index().to_sql('tstat_gene_data', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# Baseline + Tap + PSA combined tstat data by Allele\n",
    "print(\"working on tstat_allele_data\")\n",
    "final_tstat_allele.dropna(thresh=10).reset_index().to_sql('tstat_allele_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# final_tstat_allele.reset_index().to_sql('tstat_allele_data', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# MSD Baseline + Tap + PSA by Gene\n",
    "print(\"working on gene_MSD\")\n",
    "combined_MSD.to_sql('gene_MSD', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# combined_MSD.to_sql('gene_MSD', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# MSD Baseline + Tap + PSA by Allele\n",
    "print(\"working on allele_MSD\")\n",
    "allele_combined_MSD.to_sql('allele_MSD', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# allele_combined_MSD.to_sql('allele_MSD', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# Summarised PSA data (speed, kink, curve, etc.)\n",
    "print(\"working on psa_data:\") \n",
    "psa_data.to_sql('psa_summarised_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "# psa_data.to_sql('psa_summarised_data', engine, if_exists='replace', index=False, method=None)\n",
    "\n",
    "# # Melted Baseline + Tap + PSA combined tstat data by Gene\n",
    "# print(\"working on gene_profile_data\")\n",
    "# final_tstat_melted.to_sql('gene_profile_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "# # Melted Baseline + Tap + PSA combined tstat data by Allele\n",
    "# print(\"working on allele_profile_data\")\n",
    "# final_tstat_melted_allele.to_sql('allele_profile_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "\n",
    "print(\"---------- DONE ----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393ea68",
   "metadata": {},
   "source": [
    "### Use the below cell if you want output to local .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tap_psa_output.to_csv('/Users/Joseph/Desktop/PDScreen_tap_psa_output.csv', index=False)\n",
    "# final_tstat.to_csv('/Users/Joseph/Desktop/PDScreen_final_tstat.csv', index=False)\n",
    "# final_tstat_allele.to_csv('/Users/Joseph/Desktop/PDScreen_final_tstat_allele.csv', index=False)\n",
    "# combined_MSD.to_csv('/Users/Joseph/Desktop/PDScreen_combined_MSD.csv', index=False)\n",
    "# allele_combined_MSD.to_csv('/Users/Joseph/Desktop/PDScreen_combined_MSD_allele.csv', index=False)\n",
    "# psa_data.to_csv('/Users/Joseph/Desktop/PDScreen_psa_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dabe74",
   "metadata": {},
   "source": [
    "### Use the below cell to just replace/update one table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads database config values from database.ini file and validates that user and password are set.\n",
    "config = load_config()\n",
    "if (config['user'] == \"\" or config['password'] == \"\"):\n",
    "    print(\"Please set your user and password in the database.ini file.\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Creates a connection pool to PostgreSQL database using SQLAlchemy.\n",
    "engine = create_engine(f\"postgresql+psycopg://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\")\n",
    "\n",
    "# Function to insert data into PostgreSQL table, skipping duplicates based on primary keys.\n",
    "def postgres_skip_on_duplicate(pd_table, conn, keys, data_iter):\n",
    "    data = [dict(zip(keys,row)) for row in data_iter]\n",
    "    conn.execute(insert(pd_table.table).on_conflict_do_nothing(), data)\n",
    "\n",
    "\n",
    "# Complete tap response data\n",
    "print(\"working on tap_output:\") \n",
    "tap_psa_output.to_sql('tap_response_data', engine, if_exists='replace', index=False, method=None)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c616-2839-4572-af70-233af783302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # USE THIS CELL TO UPDATE ALL THE NEED TALBES (Also have baseline_output on the second line)\n",
    "\n",
    "# conn=sqlite3.connect('/Users/lavanya/Desktop/Lavanya_Test/data_updated2.db')\n",
    "\n",
    "# tap_output.to_sql('tap_response_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# baseline_output.to_sql('tap_baseline_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalize_2.reset_index().to_sql('tstat_gene_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalize_allele_2.reset_index().to_sql('tstat_allele_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalized_melted.to_sql('gene_profile_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalized_melted_allele.to_sql('allele_profile_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_MSD.to_sql('gene_MSD', conn, if_exists='append', index=False)\n",
    "\n",
    "# allele_combined_MSD.to_sql('allele_MSD', conn, if_exists='append', index=False)\n",
    "\n",
    "# # combined_Tstats_melted_sorted.to_sql('allele_phenotype_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# print(conn.total_changes)\n",
    "\n",
    "# conn.close()\n",
    "\n",
    "\n",
    "# # Want to test edge cases of pd.to_sql functionality#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f45bd-88e7-4626-9284-30f1a02024cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rankinlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
