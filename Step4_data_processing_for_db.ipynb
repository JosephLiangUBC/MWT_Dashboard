{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8b6eb7",
   "metadata": {},
   "source": [
    "# 1. Imports and File selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf3cc6-37e8-43e4-a57e-d9f3d868ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import numpy\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "import sys\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "from config import load_config\n",
    "from ipyfilechooser import FileChooser\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlite3 import Error\n",
    "from sqlite3 import IntegrityError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047872c-f454-4b21-ae5f-fbe76ded5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_directory = '/Users'\n",
    "baseline_chooser = FileChooser(starting_directory)\n",
    "display(baseline_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf95420-e48d-4d6d-964f-dbbc41cc0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_chooser=FileChooser(starting_directory)\n",
    "display(tap_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "screens = ['PD_Screen', 'ASD_Screen', 'G-Proteins_Screen', 'Glia_Genes_Screen', 'Neuron_Genes_Screen']\n",
    "\n",
    "screen_chooser = widgets.Select(options=screens, value=screens[0], description='Screen:')\n",
    "display(screen_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad41b49-c54a-41bc-b2a4-12865e70cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Screen=screen_chooser.value\n",
    "folder_path=baseline_chooser.selected_path\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdae795-4e5b-4371-acd2-40d77be2796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the baseline file\n",
    "baseline_output = pd.read_csv(baseline_chooser.selected, index_col=0).drop(columns=['index'])\n",
    "\n",
    "print(f\"\\nShape of the baseline .csv file: {baseline_output.shape}\")\n",
    "\n",
    "# Print the first five rows of the file\n",
    "baseline_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3581dfb-50a2-41f2-87d2-5ca53439c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tap file\n",
    "tap_output = pd.read_csv(tap_chooser.selected, index_col=0)\n",
    "\n",
    "print(f\"\\nShape of the tap .csv file: {tap_output.shape}\")\n",
    "\n",
    "# Print the first five rows of the file\n",
    "tap_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee66b8",
   "metadata": {},
   "source": [
    "# 2. DataFrame preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e014e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for first tap\n",
    "PD_first_tap = (\n",
    "    tap_output[(tap_output.taps==1)]\n",
    "    .reset_index().drop(columns=\"index\")\n",
    "    .rename(columns={\"dura\": \"init_dura\", \"prob\": \"init_prob\", \"speed\": \"init_speed\"}, errors=\"raise\")\n",
    ")\n",
    "\n",
    "PD_first_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for recovery taps\n",
    "PD_recov_taps = (\n",
    "    tap_output[(tap_output.taps==31)]\n",
    "    .reset_index().drop(columns=\"index\")\n",
    "    .rename(columns={\"dura\": \"recov_dura\", \"prob\": \"recov_prob\", \"speed\":\"recov_speed\"})\n",
    ")\n",
    "\n",
    "PD_recov_taps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ea9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for last three taps\n",
    "PD_final_taps = (\n",
    "    tap_output[((tap_output.taps >= 28) & (tap_output.taps <= 30))]\n",
    "    .groupby([\"dataset\", \"Date\",\"Plate_id\",\"Screen\",\"Gene\",\"Allele\",\"plate\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"dura\": \"final_dura\", \"prob\": \"final_prob\", \"speed\": \"final_speed\"}, errors=\"raise\")\n",
    ")\n",
    "\n",
    "PD_final_taps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to analyse habituation behaviour after merging first tap and final taps\n",
    "\n",
    "PD_habit_levels = pd.merge(\n",
    "    PD_first_tap, \n",
    "    PD_final_taps, \n",
    "    on =['dataset', 'plate', \"Plate_id\", \"Screen\", \"Gene\", \"Allele\", \"Date\"], how ='left'\n",
    ").drop(columns=['time_x','time_y','dist_x','dist_y', 'taps_x', 'taps_y']).dropna()\n",
    "\n",
    "PD_habit_levels['habit_dura'] = PD_habit_levels['init_dura'] - PD_habit_levels['final_dura']\n",
    "\n",
    "PD_habit_levels['habit_prob'] = PD_habit_levels['init_prob'] - PD_habit_levels['final_prob']\n",
    "\n",
    "PD_habit_levels['habit_speed'] = PD_habit_levels['init_speed'] - PD_habit_levels['final_speed']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cec40a-82bb-4783-a0a9-fa6d9fcfa6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to analyse habituation behaviour after merging with recovery taps\n",
    "\n",
    "if PD_recov_taps.empty:\n",
    "    PD_habituation = pd.merge(PD_habit_levels, PD_recov_taps, on =['dataset','plate',\"Plate_id\",\"Screen\",\"Gene\",\"Allele\",\"Date\"], how ='outer')\n",
    "else:\n",
    "    PD_habituation = pd.merge(PD_habit_levels, PD_recov_taps, on =['dataset','plate',\"Plate_id\",\"Screen\",\"Gene\",\"Allele\",\"Date\"], how ='left')\n",
    "\n",
    "if Screen not in ['Neuron_Genes_Screen', 'G-Proteins_Screen']:\n",
    "    PD_habituation = PD_habituation.dropna() \n",
    "\n",
    "PD_habituation['recovery_dura']=(PD_habituation.recov_dura-PD_habituation.init_dura)/PD_habituation.init_dura*100\n",
    "\n",
    "PD_habituation['recovery_prob']=(PD_habituation.recov_prob-PD_habituation.init_prob)/PD_habituation.init_prob*100\n",
    "\n",
    "PD_habituation['recovery_speed']=(PD_habituation.recov_speed-PD_habituation.init_speed)/PD_habituation.init_speed*100\n",
    "\n",
    "PD_habituation['memory_retention_dura']=(PD_habituation.recov_dura-PD_habituation.final_dura)\n",
    "\n",
    "PD_habituation['memory_retention_prob']=(PD_habituation.recov_prob-PD_habituation.final_prob)\n",
    "\n",
    "PD_habituation['memory_retention_speed']=(PD_habituation.recov_speed-PD_habituation.final_speed)\n",
    "\n",
    "\n",
    "# Rename `PD_habituation` to `tap_data` based on the condition below\n",
    "if Screen in ['Neuron_Genes_Screen', 'G-Proteins_Screen']:\n",
    "    tap_data=PD_habituation.dropna(subset = ['init_dura', 'init_prob', 'init_speed', 'plate', 'Date', 'Plate_id',\n",
    "       'Screen', 'dataset', 'Gene', 'Allele', 'final_dura', 'final_prob',\n",
    "       'final_speed', 'habit_dura', 'habit_prob', 'habit_speed'])\n",
    "else:\n",
    "    tap_data=PD_habituation.dropna() \n",
    "\n",
    "\n",
    "# Display final dataframe\n",
    "tap_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74308e12-a414-4899-b18f-ed97d006930d",
   "metadata": {},
   "source": [
    "# 3. Run Statistics (T-Test and sample-mean distance) on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f35b2",
   "metadata": {},
   "source": [
    "## 3.1 Generate dataframes conditioned by `baseline` (True/False) and `allele` (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76fdc5-2356-4617-8c2c-29e1685808bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_byplate(output, baseline, allele):\n",
    "    \"\"\"\n",
    "    Aggregates data by 'Plate_id','Date','Screen','dataset','Gene','Allele'\n",
    "\n",
    "    Parameters:\n",
    "        output (pd.DataFrame): Input DataFrame (either baseline_output or tap_data)\n",
    "        baseline (boolean): whether data is baseline (True) or tap response (False)\n",
    "        allele (boolean): group by allele (True) or group by gene (False)\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with plate-level averages\n",
    "    \"\"\"\n",
    "\n",
    "    # columns to delete if baseline = True\n",
    "    drop_col_base=['Plate_id','n','Number','Time','Screen','Date','Allele']\n",
    "\n",
    "    # columns to delete if baseline = False\n",
    "    drop_col_taps=['Plate_id','Screen','Date','Allele','dist','plate','time',\n",
    "                   'taps','recov_dura','recov_prob','recov_speed']\n",
    "    \n",
    "    drop_col = drop_col_base if baseline else drop_col_taps\n",
    "\n",
    "    drop_col.append('Gene') if allele else drop_col.append('dataset')\n",
    "     \n",
    "    output_byplate = output.groupby(\n",
    "        by=['Plate_id','Date','Screen','dataset','Gene','Allele'],\n",
    "        as_index=False).mean().drop(columns=drop_col)\n",
    "    \n",
    "    return output_byplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc76ca",
   "metadata": {},
   "source": [
    "#### 3.1.1 `baseline` = True, `allele` = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_output_byplate=get_output_byplate(baseline_output, baseline= True, allele=False)\n",
    "\n",
    "print(f\"Shape: {baseline_output_byplate.shape}\")\n",
    "\n",
    "baseline_output_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e0c7f",
   "metadata": {},
   "source": [
    "#### 3.1.2 `baseline` = False, `allele` = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_data_byplate=get_output_byplate(tap_data, baseline=False, allele=False)\n",
    "\n",
    "print(f\"Shape: {tap_data_byplate.shape}\")\n",
    "\n",
    "tap_data_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21990731",
   "metadata": {},
   "source": [
    "#### 3.1.3 `baseline` = True, `allele` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49800e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_output_allele_byplate = get_output_byplate(baseline_output,baseline=True, allele=True)\n",
    "\n",
    "print(f\"Shape: {baseline_output_allele_byplate.shape}\")\n",
    "\n",
    "baseline_output_allele_byplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc810907",
   "metadata": {},
   "source": [
    "#### 3.1.4 `baseline` = False, `allele` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_data_allele_byplate = get_output_byplate(tap_data, baseline=False, allele=True)\n",
    "\n",
    "print(f\"Shape: {tap_data_allele_byplate.shape}\")\n",
    "\n",
    "tap_data_allele_byplate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304d782-9424-4068-a3f4-4982b1be21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tap_data_allele_byplate[tap_data_allele_byplate.dataset=='N2_XJ1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33e2a9",
   "metadata": {},
   "source": [
    "## 3.2 Calculate Mean Distances and CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10502cca-0ab9-4bd5-9801-7a247a6af822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_phenotypes(df):\n",
    "    ''' \n",
    "    Splits a multi-column DataFrame into a list of DataFrames, each containing one phenotype\n",
    "\n",
    "    input: \n",
    "        df (pd.DataFrame): dataframe with multiple columns (1st column is the index, the other are phenotypes)\n",
    "\n",
    "    returns:\n",
    "        list_phenotypes_df: list with 2 columns - one for index and one for phenotype, \n",
    "            for how many phenotypes there are in the input\n",
    "    '''\n",
    "    list_phenotypes_df = []\n",
    "    index = df.columns[0]\n",
    "    for i in df.columns[1:]:\n",
    "        list_phenotypes_df.append(df[[index, i]].copy())\n",
    "\n",
    "    return list_phenotypes_df\n",
    "\n",
    "\n",
    "\n",
    "def ci95(df):\n",
    "    \"\"\"\n",
    "    input: df of 4 columns: index, mean, count, std\n",
    "\n",
    "    returns: df of 6 columns: index, mean, count, std, ci95_hi, ci95_low\n",
    "\n",
    "    \"\"\"\n",
    "    for metric in df.columns.levels[0]:\n",
    "        if metric == 'Gene':\n",
    "            pass\n",
    "        else:\n",
    "            ci95_hi = []\n",
    "            ci95_lo = []\n",
    "            for i in df[metric].index:\n",
    "                m = df[metric]['mean'].loc[i]\n",
    "                c = df[metric]['count'].loc[i]\n",
    "                s = df[metric]['sem'].loc[i]\n",
    "                ci95_hi.append(stats.t.interval(confidence=0.95, df=c-1, loc=m, scale=s)[1])\n",
    "                ci95_lo.append(stats.t.interval(confidence=0.95, df=c-1, loc=m, scale=s)[0])\n",
    "            df[metric,'ci95_hi'] = ci95_hi\n",
    "            df[metric,'ci95_lo'] = ci95_lo\n",
    "            # df[metric,'ci95']=list(zip(ci95_lo,ci95_hi))\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_MSD(list_of_dfs, by):\n",
    "    new_list_of_dfs = []\n",
    "    \n",
    "    for df in list_of_dfs:\n",
    "        # Get phenotype column name (assuming 2nd column is the metric)\n",
    "        pheno_col = df.columns[1]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = df.groupby(by)[df.columns[1]].agg(['mean', 'count', 'sem'])\n",
    "\n",
    "        \n",
    "        # DEBUGGED: Convert to MultiIndex if needed (more robust version)\n",
    "        if not isinstance(stats.columns, pd.MultiIndex):\n",
    "            stats.columns = pd.MultiIndex.from_tuples([(pheno_col, col) for col in stats.columns])\n",
    "        \n",
    "        # Calculate CI\n",
    "        stats_2 = ci95(stats)\n",
    "        \n",
    "        # Get N2 control data\n",
    "        if Screen == \"Neuron_Genes_Screen\":\n",
    "            N2_mask = stats_2.index == 'N2' if by == \"Gene\" else stats_2.index.isin(['N2_XJ1','N2_N2'])\n",
    "        else:\n",
    "            N2_mask = stats_2.index == 'N2'\n",
    "            \n",
    "        N2_data = stats_2[N2_mask]\n",
    "        \n",
    "        # Subtract N2 values\n",
    "        stats_2.iloc[:, 0] -= N2_data.iloc[0, 0]  # mean\n",
    "        stats_2.iloc[:, 3] -= N2_data.iloc[0, 0]  # ci95_hi\n",
    "        stats_2.iloc[:, 4] -= N2_data.iloc[0, 0]  # ci95_low\n",
    "        \n",
    "        new_list_of_dfs.append(stats_2)\n",
    "    \n",
    "    return new_list_of_dfs\n",
    "\n",
    "\n",
    "\n",
    "def get_MSD(list_MSD):\n",
    "    '''\n",
    "    input: List of dataframes, each representing a phenotype with calculated MSD.\n",
    "\n",
    "    returns: Single combined dataframe joining all input dataframes with MSD values.\n",
    "    '''\n",
    "    for a in list_MSD:\n",
    "        if a.columns.levels[0] == list_MSD[0].columns.levels[0]:\n",
    "            MSD=a\n",
    "        else:\n",
    "            MSD=MSD.join(a)\n",
    "    return MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_MSD(baseline_byplate,tap_byplate, by=['Gene','dataset']):\n",
    "    \"\"\"\n",
    "    Combines MSD datafram from baseline plates and tap plates\n",
    "\n",
    "    input:\n",
    "        - baseline_byplate: baseline data by plate\n",
    "        - tap_byplate: tap data by plate\n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "    returns:\n",
    "        - combined MSD dataframe\n",
    "    \"\"\"\n",
    "    list_baseline_MSD=calculate_MSD(extract_phenotypes(baseline_byplate), by=by)\n",
    "\n",
    "    list_tap_MSD=calculate_MSD(extract_phenotypes(tap_byplate), by=by)\n",
    "\n",
    "    baseline_MSD = get_MSD(list_baseline_MSD)\n",
    "    \n",
    "    tap_MSD = get_MSD(list_tap_MSD)\n",
    "\n",
    "    combined_MSD = baseline_MSD.join(tap_MSD, on=by)\n",
    "\n",
    "    combined_MSD=combined_MSD.rename(columns={\"habit_dura\":\"Habituation of Response Duration\",\n",
    "                                         \"habit_prob\": \"Habituation of Respones Probability\",\n",
    "                                         \"habit_speed\":\"Habituation of Response Speed\",\n",
    "                                         \"init_dura\": \"Initial Response Duration\",\n",
    "                                         \"init_prob\": \"Initial Response Probability\",\n",
    "                                         \"init_speed\": \"Initial Response Speed\",\n",
    "                                         \"final_dura\": \"Final Response Duration\",\n",
    "                                         \"final_prob\": \"Final Response Probability\",\n",
    "                                         \"final_speed\": \"Final Response Speed\",\n",
    "                                         \"recovery_dura\": \"Spontaneous Recovery of Response Duration\",\n",
    "                                         \"recovery_prob\": \"Spontaneous Recovery of Response Probability\",\n",
    "                                         \"recovery_speed\": \"Spontaneous Recovery of Response Speed\",\n",
    "                                         \"memory_retention_dura\": \"Memory Retention of Response Duration\",\n",
    "                                         \"memory_retention_prob\": \"Memory Retention of Response Probability\",\n",
    "                                         \"memory_retention_speed\": \"Memory Retention of Response Speed\"})\n",
    "\n",
    "    combined_MSD=combined_MSD.reset_index()\n",
    "    combined_MSD.columns = combined_MSD.columns.to_flat_index().str.join('-')\n",
    "    combined_MSD=combined_MSD.rename(columns={by+\"-\": by})\n",
    "    combined_MSD['Screen']=Screen\n",
    "    \n",
    "    return combined_MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3396554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSD(list_of_dfs, by):\n",
    "    new_list_of_dfs = []\n",
    "    \n",
    "    for df in list_of_dfs:\n",
    "        # Get phenotype column name (assuming 2nd column is the metric)\n",
    "        pheno_col = df.columns[1]\n",
    "        \n",
    "        # Create proper MultiIndex structure\n",
    "        stats = df.groupby(by)[df.columns[1]].agg(['mean', 'count', 'sem'])\n",
    "\n",
    "        \n",
    "        # Convert to MultiIndex if needed (more robust version)\n",
    "        if not isinstance(stats.columns, pd.MultiIndex):\n",
    "            stats.columns = pd.MultiIndex.from_tuples([(pheno_col, col) for col in stats.columns])\n",
    "        \n",
    "        # Now ci95() will work\n",
    "        stats_2 = ci95(stats)\n",
    "        \n",
    "        # Get N2 control data\n",
    "        if Screen == \"Neuron_Genes_Screen\":\n",
    "            N2_mask = stats_2.index == 'N2' if by == \"Gene\" else stats_2.index.isin(['N2_XJ1','N2_N2'])\n",
    "        else:\n",
    "            N2_mask = stats_2.index == 'N2'\n",
    "            \n",
    "        N2_data = stats_2[N2_mask]\n",
    "        \n",
    "        # Subtract N2 values\n",
    "        stats_2.iloc[:, 0] -= N2_data.iloc[0, 0]  # mean\n",
    "        stats_2.iloc[:, 3] -= N2_data.iloc[0, 0]  # ci95_hi\n",
    "        stats_2.iloc[:, 4] -= N2_data.iloc[0, 0]  # ci95_low\n",
    "        \n",
    "        new_list_of_dfs.append(stats_2)\n",
    "    \n",
    "    return new_list_of_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd616c75",
   "metadata": {},
   "source": [
    "### 3.2.1 Gene-level SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e692a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_MSD=get_combined_MSD(baseline_output_byplate,\n",
    "                              tap_data_byplate, \n",
    "                              by='Gene')\n",
    "\n",
    "combined_MSD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e39002-cc71-4b7e-8404-6fd5d9eaccef",
   "metadata": {},
   "source": [
    "### 3.2.2 Allele-level SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_combined_MSD=get_combined_MSD(baseline_output_allele_byplate,\n",
    "                                     tap_data_allele_byplate, \n",
    "                                     by='dataset')\n",
    "\n",
    "allele_combined_MSD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634a41e",
   "metadata": {},
   "source": [
    "## 3.3 T-Stat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_metrics(by=[\"Gene\",\"dataset\"]):\n",
    "    \"\"\"\n",
    "    Create a list of empty dataframe and list of metrics for baseline analysis\n",
    "\n",
    "    input:\n",
    "        by (list): what to group by \"Gene\" or \"dataset\"\n",
    "        \n",
    "    returns:\n",
    "        list_baseline_Tstats: dataframes to store t-statistics\n",
    "        list_baseline_metrics: dataframes to store metic names\n",
    "    \"\"\"\n",
    "    PD_baseline_instantspeed_T=pd.DataFrame(columns = [by,\"Instantaneous Speed\"])\n",
    "    PD_baseline_intspeed_T=pd.DataFrame(columns = [by,\"Interval Speed\"])\n",
    "    PD_baseline_bias_T=pd.DataFrame(columns = [by,\"Bias\"])\n",
    "    PD_baseline_morphwidth_T=pd.DataFrame(columns = [by,\"Morphwidth\"])\n",
    "    PD_baseline_midline_T=pd.DataFrame(columns = [by,\"Midline\"])\n",
    "    PD_baseline_area_T=pd.DataFrame(columns = [by,\"Area\"])\n",
    "    PD_baseline_angularspeed_T=pd.DataFrame(columns = [by,\"Angular Speed\"])\n",
    "    PD_baseline_aspectratio_T=pd.DataFrame(columns = [by,\"Aspect Ratio\"])\n",
    "    PD_baseline_kink_T=pd.DataFrame(columns = [by,\"Kink\"])\n",
    "    PD_baseline_curve_T=pd.DataFrame(columns = [by,\"Curve\"])\n",
    "    PD_baseline_crab_T=pd.DataFrame(columns = [by,\"Crab\"])\n",
    "    PD_baseline_pathlength_T=pd.DataFrame(columns = [by,\"Pathlength\"])\n",
    "\n",
    "    list_baseline_Tstats=[PD_baseline_instantspeed_T,\n",
    "                        PD_baseline_intspeed_T,\n",
    "                        PD_baseline_bias_T,\n",
    "                        PD_baseline_morphwidth_T,\n",
    "                        PD_baseline_midline_T,\n",
    "                        PD_baseline_area_T,\n",
    "                        PD_baseline_angularspeed_T,\n",
    "                        PD_baseline_aspectratio_T,\n",
    "                        PD_baseline_kink_T,\n",
    "                        PD_baseline_curve_T,\n",
    "                        PD_baseline_crab_T,\n",
    "                        PD_baseline_pathlength_T]\n",
    "\n",
    "    list_baseline_metrics=[\"Instantaneous Speed\",\n",
    "                        \"Interval Speed\",\n",
    "                        \"Bias\",\n",
    "                        \"Morphwidth\",\n",
    "                        \"Midline\",\n",
    "                        \"Area\",\n",
    "                        \"Angular Speed\",\n",
    "                        \"Aspect Ratio\",\n",
    "                        \"Kink\",\n",
    "                        \"Curve\",\n",
    "                        \"Crab\",\n",
    "                        \"Pathlength\"]\n",
    "    \n",
    "    return list_baseline_Tstats, list_baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tap_metrics(by=[\"Gene\",\"dataset\"]):\n",
    "    \"\"\"\n",
    "    Create a list of empty dataframes and list of metrics for tap analysis\n",
    "\n",
    "    input:\n",
    "        by (list): what to group by \"Gene\" or \"dataset\"\n",
    "        \n",
    "    returns:\n",
    "        list_tap_Tstats: dataframes to store t-statistics\n",
    "        list_tap_metrics: dataframes to store metic names\n",
    "    \"\"\"\n",
    "    recovery_dura=pd.DataFrame(columns = [by,\"Recovery Duration\"])\n",
    "    recovery_prob=pd.DataFrame(columns = [by,\"Recovery Probability\"])\n",
    "    recovery_speed=pd.DataFrame(columns = [by,\"Recovery Speed\"])\n",
    "    memory_retention_dura=pd.DataFrame(columns = [by,\"Memory Retention Duration\"])\n",
    "    memory_retention_prob=pd.DataFrame(columns = [by,\"Memory Retention Probability\"])\n",
    "    memory_retention_speed=pd.DataFrame(columns = [by,\"Memory Retention Speed\"])\n",
    "    init_dura=pd.DataFrame(columns = [by,\"Initial Duration\"])\n",
    "    init_prob=pd.DataFrame(columns = [by,\"Initial Probability\"])\n",
    "    init_speed=pd.DataFrame(columns = [by,\"Initial Speed\"])\n",
    "    final_dura=pd.DataFrame(columns = [by,\"Final Duration\"])\n",
    "    final_prob=pd.DataFrame(columns = [by,\"Final Probability\"])\n",
    "    final_speed=pd.DataFrame(columns = [by,\"Final Speed\"])\n",
    "    hab_dura=pd.DataFrame(columns = [by,\"Habituation of Duration\"])\n",
    "    hab_prob=pd.DataFrame(columns = [by,\"Habituation of Probability\"])\n",
    "    hab_speed=pd.DataFrame(columns = [by,\"Habituation of Speed\"])\n",
    "\n",
    "    list_tap_Tstats = [recovery_dura,\n",
    "                    recovery_prob,\n",
    "                    recovery_speed,\n",
    "                    memory_retention_dura,\n",
    "                    memory_retention_prob,\n",
    "                    memory_retention_speed,\n",
    "                    init_dura,\n",
    "                    init_prob,\n",
    "                    init_speed,\n",
    "                    final_dura,\n",
    "                    final_prob,\n",
    "                    final_speed,\n",
    "                    hab_dura,\n",
    "                    hab_prob,\n",
    "                    hab_speed]\n",
    "    \n",
    "    list_tap_metrics = [\"recovery_dura\",\n",
    "                        \"recovery_prob\",\n",
    "                        \"recovery_speed\",\n",
    "                        \"memory_retention_dura\",\n",
    "                        \"memory_retention_prob\",\n",
    "                        \"memory_retention_speed\",\n",
    "                        \"init_dura\",\n",
    "                        \"init_prob\",\n",
    "                        \"init_speed\",\n",
    "                        \"final_dura\",\n",
    "                        \"final_prob\",\n",
    "                        \"final_speed\",\n",
    "                        \"habit_dura\",\n",
    "                        \"habit_prob\",\n",
    "                        \"habit_speed\"]\n",
    "    \n",
    "    return list_tap_Tstats, list_tap_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62abf35-b324-4b96-9328-91df56e05470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTest(Type, DF_ref, output, by=[\"Gene\", \"dataset\"]):\n",
    "    \"\"\"\n",
    "    Perform two sample t-test for each unique Gene/dataset column in the Df_ref\n",
    "    input: \n",
    "        - a:column name of values \n",
    "        - DF_ref:reference dataframe\n",
    "        - output: output df to store results in \n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "        \n",
    "    \"\"\"\n",
    "    for a in DF_ref[by].unique():\n",
    "        Tstat_a =ttest_ind(DF_ref[DF_ref.dataset == a][Type], DF_ref[DF_ref.Allele.isin([\"XJ1\",\"N2\"])][Type],equal_var=False)[0]\n",
    "        Tstat_g= ttest_ind(DF_ref[DF_ref.Gene == a][Type], DF_ref[DF_ref.Gene == \"N2\"][Type],equal_var=False)[0]\n",
    "        Tstat = Tstat_g if by==\"Gene\" else Tstat_a\n",
    "        row=[a, Tstat]\n",
    "        output.loc[len(output)]=row\n",
    "    # print(output)\n",
    "\n",
    "def do_TTest(by=[\"Gene\", \"dataset\"], baseline=[\"true\", \"false\"]):\n",
    "    \"\"\"\n",
    "    Perform TTest function for each unique Gene/dataset column in baseline_output/tap_data\n",
    "    \n",
    "    input: \n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "        - baseline: whether or not to use baseline data\n",
    "\n",
    "    returns: sorted T-statistics dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    if baseline==\"true\":\n",
    "        list_Tstats, list_metrics = baseline_metrics(by)\n",
    "        data = baseline_output\n",
    "    else:\n",
    "        list_Tstats,list_metrics = tap_metrics(by)\n",
    "        data =tap_data\n",
    "    for x in data[by].unique():\n",
    "        if Screen==\"Neuron_Genes_Screen\":\n",
    "            condition = x in ([\"N2\"] if by == \"Gene\" else [\"N2_XJ1\", \"N2_N2\"])\n",
    "        else:\n",
    "            condition = (x ==\"N2\")\n",
    "        if condition:\n",
    "            pass\n",
    "        else:\n",
    "            output_gene=data[data[by]==x]\n",
    "            gene_data=data[data['Date'].isin(output_gene['Date'].unique())]\n",
    "            if Screen==\"Neuron_Genes_Screen\":\n",
    "                gene_data_final = gene_data[gene_data[by].isin(['N2', x])] if by==\"Gene\" else gene_data[gene_data[by].isin(['N2_N2','N2_XJ1', x])]\n",
    "            else:\n",
    "                gene_data_final = gene_data[gene_data[by].isin(['N2', x])]\n",
    "\n",
    "            for a,b in zip(list_metrics, list_Tstats):\n",
    "                TTest(a, gene_data_final, b, by) #calls t test function\n",
    "    \n",
    "    PD_Tstats=pd.DataFrame()\n",
    "    for a in list_Tstats:\n",
    "        b=a.groupby([by], as_index=False).mean()\n",
    "        if b.columns.values[1] == list_Tstats[0].columns.values[1]:\n",
    "            PD_Tstats=b\n",
    "        else:\n",
    "            PD_Tstats=PD_Tstats.join(b.iloc[:,1])\n",
    "            \n",
    "    PD_Tstats=PD_Tstats.set_index(by)\n",
    "    \n",
    "    return PD_Tstats\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7965278",
   "metadata": {},
   "source": [
    "### T-stat on Baseline data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5784896-b993-4ecb-9ae9-c168d7469d90",
   "metadata": {},
   "source": [
    "### 3.3.1 Allele-level T-stat analysis of baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc477df9-91aa-41d6-a527-c61d20f99fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_baseline_Tstats_allele = do_TTest(\"dataset\", baseline=\"true\") # get sorted T-statistics DataFrame \n",
    "\n",
    "# PD_baseline_Tstats_allele_sorted=PD_baseline_Tstats_allele.sort_index()\n",
    "\n",
    "PD_baseline_Tstats_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6e5cc-a2b0-4fd8-9bc4-668b1cc22d5e",
   "metadata": {},
   "source": [
    "### 3.3.2 Gene-level T-stat analysis of baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ea9e3-1121-4b1c-ac15-77bcef16cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_baseline_Tstats=do_TTest(\"Gene\", baseline=\"true\") # get sorted T-statistics DataFrame \n",
    "\n",
    "# PD_baseline_Tstats_sorted=PD_baseline_Tstats.sort_index()\n",
    "\n",
    "PD_baseline_Tstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80323af7-e75f-4678-b5dd-810a7607fc83",
   "metadata": {},
   "source": [
    "### T-stat analysis for tap-response data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c679a-166c-43d0-946e-226ee9a20c1d",
   "metadata": {},
   "source": [
    "### 3.3.3 Allele level T-stat analysis of tap response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4585676",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_habituation_Tstats_allele = do_TTest(\"dataset\", baseline=\"false\") # get sorted T-statistics DataFrame \n",
    "\n",
    "# PD_habituation_Tstats_allele_sorted=PD_habituation_Tstats_allele.sort_index()\n",
    "\n",
    "PD_habituation_Tstats_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f44a6d-6632-4e0f-8c58-a7060daf756d",
   "metadata": {},
   "source": [
    "### 3.3.4 Gene-level T-stat analysis of Tap response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bb7d2-d1e7-4227-a056-0ca0e1d10c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PD_habituation_Tstats = do_TTest(\"Gene\", baseline=\"false\") # get sorted T-statistics DataFrame \n",
    "\n",
    "PD_habituation_Tstats_sorted=PD_habituation_Tstats.sort_index()\n",
    "\n",
    "PD_habituation_Tstats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3071bf3-afd5-49e8-baa4-7e37dd120383",
   "metadata": {},
   "source": [
    "# 4. Merging t-stat data into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16271ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_cols(combined):\n",
    "    \"\"\"\n",
    "    Reorders columns in the combined dataframe. \n",
    "    (pops specific columns[\"Area\", \"Midline\", \"Morphwidth\", \"Angular Speed\"] and\n",
    "    reinserts at different positions)\n",
    "\n",
    "    input:\n",
    "        combined: dataframe with columns to be reordered\n",
    "\n",
    "    returns: \n",
    "        NA    \n",
    "        \n",
    "    \"\"\"\n",
    "    first_col=combined.pop(\"Area\")\n",
    "    combined.insert(0,\"Area\",first_col)\n",
    "\n",
    "    first_col=combined.pop(\"Midline\")\n",
    "    combined.insert(0,\"Midline\",first_col)\n",
    "\n",
    "    first_col=combined.pop(\"Morphwidth\")\n",
    "    combined.insert(0,\"Morphwidth\",first_col)\n",
    "\n",
    "    first_col=combined.pop(\"Angular Speed\")\n",
    "    combined.insert(5,\"Angular Speed\",first_col)\n",
    "\n",
    "def pop_last(combined):\n",
    "    \"\"\"\n",
    "    Reorders the last three columns of the combined dataframe.\n",
    "    input:\n",
    "        combined: dataframe with columns to be reordered\n",
    "\n",
    "    \"\"\"\n",
    "    last_col=combined.pop(\"Spontaneous Recovery of Response Duration\")\n",
    "    combined.insert(26,\"Spontaneous Recovery of Response Duration\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Spontaneous Recovery of Response Probability\")\n",
    "    combined.insert(26,\"Spontaneous Recovery of Response Probability\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Spontaneous Recovery of Response Speed\")\n",
    "    combined.insert(26,\"Spontaneous Recovery of Response Speed\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Memory Retention of Response Duration\")\n",
    "    combined.insert(26,\"Memory Retention of Response Duration\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Memory Retention of Response Probability\")\n",
    "    combined.insert(26,\"Memory Retention of Response Probability\",last_col)\n",
    "\n",
    "    last_col=combined.pop(\"Memory Retention of Response Speed\")\n",
    "    combined.insert(26,\"Memory Retention of Response Speed\",last_col)\n",
    "\n",
    "def rename_columns(df):\n",
    "    '''\n",
    "    Renames columns in the input dataframe\n",
    "    input:\n",
    "        combined: dataframe with columns to be renamed   \n",
    "    returns:\n",
    "        input dataframe with renamed columns \n",
    "    '''\n",
    "    renames = {\n",
    "        \"Habituation of Duration\": \"Habituation of Response Duration\",\n",
    "        \"Habituation of Probability\": \"Habituation of Respones Probability\",\n",
    "        \"Habituation of Speed\": \"Habituation of Response Speed\",\n",
    "        \"Initial Duration\": \"Initial Response Duration\",\n",
    "        \"Initial Probability\": \"Initial Response Probability\",\n",
    "        \"Initial Speed\": \"Initial Response Speed\",\n",
    "        \"Final Duration\": \"Final Response Duration\",\n",
    "        \"Final Probability\": \"Final Response Probability\",\n",
    "        \"Final Speed\": \"Final Response Speed\",\n",
    "        \"Recovery Duration\": \"Spontaneous Recovery of Response Duration\",\n",
    "        \"Recovery Probability\": \"Spontaneous Recovery of Response Probability\",\n",
    "        \"Recovery Speed\": \"Spontaneous Recovery of Response Speed\",\n",
    "        \"Memory Retention Duration\": \"Memory Retention of Response Duration\",\n",
    "        \"Memory Retention Probability\": \"Memory Retention of Response Probability\",\n",
    "        \"Memory Retention Speed\": \"Memory Retention of Response Speed\"\n",
    "    }\n",
    "    return df.rename(columns=renames)\n",
    "\n",
    "def merge_Tstats(baseline, habituation, by=[\"Gene\", \"dataset\"], Screen='PD_Screen'):\n",
    "    \"\"\"\n",
    "    merge two dataframes based on the Gene/dataset\n",
    "    normalize the merged dataframe and then return it with melted version\n",
    "\n",
    "    input:\n",
    "        - baseline: baseline dataframe to merge\n",
    "        - habituation: habituation dataframe to merge\n",
    "        - by: what to group by \"Gene\" or \"dataset\"\n",
    "    \"\"\"\n",
    "\n",
    "    #merge baseline and habituation data\n",
    "    combined_Tstats = pd.merge(baseline, habituation, on=by, how='left')\n",
    "    combined_Tstats = combined_Tstats.sort_index() # sort by index\n",
    "\n",
    "    #normalise combined dataframe by subtracting mean and div by sd\n",
    "    combined_Tstats_normalized = (combined_Tstats-combined_Tstats.mean())/combined_Tstats.std()\n",
    "\n",
    "    if by==\"dataset\" and Screen==\"Neuron_Genes_Screen\":\n",
    "        combined_Tstats_normalized_2 = combined_Tstats_normalized-combined_Tstats_normalized[combined_Tstats_normalized.index==\"N2_XJ1\"].squeeze()\n",
    "    else :\n",
    "        combined_Tstats_normalized_2 = combined_Tstats_normalized-combined_Tstats_normalized[combined_Tstats_normalized.index==\"N2\"].squeeze()  \n",
    "\n",
    "    pop_cols(combined_Tstats) #reorder columns\n",
    "\n",
    "    #rename columns of combined and normalized df\n",
    "    combined_Tstats=rename_columns(combined_Tstats)\n",
    "    combined_Tstats_normalized_2=rename_columns(combined_Tstats_normalized_2)\n",
    "    \n",
    "    pop_cols(combined_Tstats_normalized_2) # reorder columns\n",
    "    pop_last(combined_Tstats_normalized_2) # reorder columns\n",
    "\n",
    "    # Melt the combined dataframe\n",
    "    combined_Tstats_melted=combined_Tstats.reset_index()\n",
    "    combined_Tstats_melted=pd.melt(combined_Tstats_melted, id_vars=[by],\n",
    "                                var_name='Metric',\n",
    "                                value_name='T_score')\n",
    "    \n",
    "    # Sort the melted dataframe by T_score\n",
    "    combined_Tstats_melted_sorted=combined_Tstats_melted.sort_values(by=['T_score'])\n",
    "\n",
    "    # Melt the normalized dataframe\n",
    "    combined_Tstats_normalized_melted=combined_Tstats_normalized_2.reset_index()\n",
    "    combined_Tstats_normalized_melted=pd.melt(combined_Tstats_normalized_melted, id_vars=[by],\n",
    "                                                   var_name='Metric',\n",
    "                                                   value_name='T_score')\n",
    "\n",
    "    #add Screen column to df and its melted version\n",
    "    combined_Tstats_normalized_2['Screen']=Screen\n",
    "    combined_Tstats_normalized_melted['Screen']=Screen\n",
    "\n",
    "    return combined_Tstats_normalized_2,combined_Tstats_normalized_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c436e-1fd2-4bd1-8dd4-53517d4d0f4a",
   "metadata": {},
   "source": [
    "## 4.1 Gene-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eacd88-edb5-4e98-9f49-2d4508cf40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Tstats_normalize_2, combined_Tstats_normalized_melted = merge_Tstats(PD_baseline_Tstats,PD_habituation_Tstats, \"Gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Tstats_normalize_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Tstats_normalized_melted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da0e1e-d702-408f-b278-2a05b39ba999",
   "metadata": {},
   "source": [
    "## 4.2 Allele level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16521a12-8c86-4310-9455-09054ed08b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Tstats_normalize_allele_2, combined_Tstats_normalized_melted_allele = merge_Tstats(PD_baseline_Tstats_allele,PD_habituation_Tstats_allele, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0af26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Tstats_normalize_allele_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Tstats_normalized_melted_allele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4915fd6-beba-45a7-9575-346dfe679285",
   "metadata": {},
   "source": [
    "# 5. Save data to database (sqlite3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a06cb-457b-4d9e-bb11-6e6042b6b65b",
   "metadata": {},
   "source": [
    "#### A janky way to add data and update the sql \n",
    "\n",
    "1. Read table to pd.DataFrame\n",
    "2. Add new data to pd.DataFrame\n",
    "3. Replace old table with newly updated pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb60361-29ff-45d7-8d74-0e8f3aed8ac4",
   "metadata": {},
   "source": [
    "# Primary Keys For Each SQL Table:\n",
    "\n",
    "####  -- Gene_Allele_WormBaseID:\n",
    "WBGene, WBAllele\n",
    "#### -- alleleMSD:\n",
    "dataset, Screen\n",
    "#### -- gene_MSD:\n",
    "Gene, Screen\n",
    "#### -- allele_profile_data:\n",
    "dataset, Metric, Screen\n",
    "#### -- gene_profile_data:\n",
    "Gene, Metric, Screen\n",
    "#### -- tap_baseline_data:\n",
    "Time, Plate_id, Date, Screen, dataset\n",
    "#### -- tap_response_data:\n",
    "plate, Date, Plate_id, Screen, taps, dataset\n",
    "#### -- tstat_allele_data:\n",
    "dataset, Screen\n",
    "#### -- tstat_gene_data:\n",
    "Gene, Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526bccb-d0e3-48b8-9483-6496927a9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code might be useful as reference for accessing server???? Keep here just in case.\n",
    "\n",
    "# # tap_url = 'https://osf.io/du9bj/files/osfstorage/650a2f9f1e76a4230e8a99a5?raw=true'\n",
    "# tap_url='https://github.com/MyYummyPancake/NRSC510B/blob/main/tap_output.csv?raw=true'\n",
    "# # s=requests.get(tap_url).content\n",
    "# # tap_output=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "# tap_output=pd.read_csv(tap_url, on_bad_lines='skip', index_col=0)\n",
    "# print(tap_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbda4f1-3d27-4dfe-a6bd-585b64f0d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Gene      Screen  Morphwidth   Midline      Area  Instantaneous Speed  Interval Speed  Angular Speed      Bias  Aspect Ratio      Kink     Curve      Crab  Pathlength  Initial Response Duration  Initial Response Probability  Initial Response Speed  Final Response Duration  Final Response Probability  Final Response Speed  Habituation of Response Duration  Habituation of Respones Probability  Habituation of Response Speed  Spontaneous Recovery of Response Duration  Spontaneous Recovery of Response Probability  Spontaneous Recovery of Response Speed  Memory Retention of Response Duration  Memory Retention of Response Probability  Memory Retention of Response Speed\n",
      "0  C29E4.10   PD_Screen   -0.640408 -0.176441 -0.403961             0.915419        0.931846       1.240604  1.035898     -0.245481 -0.567404 -0.090605  1.336180    0.620272                  -0.365292                     -0.986789                0.377583                -2.053517                   -0.507668             -0.372798                          0.050655                            -1.014767                       1.063643                                  -1.357953                                     -0.105083                               -0.579105                              -0.309472                                 -1.296940                            0.997838\n",
      "1  F32D8.13   PD_Screen    0.769424  0.107726  0.400414            -0.249896       -0.124196      -0.490920 -0.002724     -0.013284 -0.141453 -0.316163 -0.696359   -0.904122                   0.474027                     -0.391259               -0.447979                 0.196402                   -0.526929              0.211762                          0.319221                             0.769273                      -0.957938                                  -2.191273                                     -0.400107                                0.790774                              -0.637259                                  0.110810                           -0.405119\n",
      "2   F35C8.1   PD_Screen    0.056609 -0.414394 -0.092872            -0.906096       -0.613264      -0.671270 -0.425745     -0.212686 -0.441041 -1.123235 -0.723614    0.492179                   0.746751                      0.335474               -0.528542                -0.303629                    2.441803             -0.888878                          1.053403                            -1.412300                       0.062665                                   0.762825                                      1.168973                               -0.081815                               1.160212                                  0.021481                            0.022841\n",
      "3   F53B2.5   PD_Screen   -0.298474 -0.175479 -0.373034             2.597156        1.617509       2.621418  2.685205      0.607503  0.186272  0.204051  0.520894   -0.146700                   0.840339                      0.317993                1.234984                 1.400829                   -0.138618             -0.119670                          0.135423                             0.521581                       2.713371                                   0.589321                                     -0.787701                               -1.225389                               0.576600                                 -0.295054                            1.495895\n",
      "4  F54B11.5   PD_Screen   -0.825161 -0.414573 -0.694198             0.676922        0.706063       0.901502  0.724467     -0.411191 -0.353748  0.038151  1.096677    0.114611                  -0.210218                     -1.130804                0.382023                -0.094544                   -1.199466              0.180684                         -0.177923                            -0.726917                       0.807068                                  -0.140703                                     -0.604587                               -1.292089                              -0.124812                                 -0.503133                           -0.623624\n",
      "5   F35C8.1  PD_Screen1    0.056609 -0.414394 -0.092872            -0.906096       -0.613264      -0.671270 -0.425745     -0.212686 -0.441041 -1.123235 -0.723614    0.492179                   0.746751                      0.335474               -0.528542                -0.303629                    2.441803             -0.888878                          1.053403                            -1.412300                       0.062665                                   0.762825                                      1.168973                               -0.081815                               1.160212                                  0.021481                            0.022841\n",
      "6       FJO   PD_Screen   -0.825161 -0.414573 -0.694198             0.676922        0.706063       0.901502  0.724467     -0.411191 -0.353748  0.038151  1.096677    0.114611                  -0.210218                     -1.130804                0.382023                -0.094544                   -1.199466              0.180684                         -0.177923                            -0.726917                       0.807068                                  -0.140703                                     -0.604587                               -1.292089                              -0.124812                                 -0.503133                           -0.623624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### This code will connect to PostgreSQL database and write non-duplicate data into the database tables.\n",
    "\n",
    "# Loads database config values from database.ini file and validates that user and password are set.\n",
    "config = load_config()\n",
    "if (config['user'] == \"\" or config['password'] == \"\"):\n",
    "    print(\"Please set your user and password in the database.ini file.\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Creates a connection pool to PostgreSQL database using SQLAlchemy.\n",
    "engine = create_engine(f\"postgresql+psycopg://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\")\n",
    "\n",
    "# Function to insert data into PostgreSQL table, skipping duplicates based on primary keys.\n",
    "def postgres_skip_on_duplicate(pd_table, conn, keys, data_iter):\n",
    "    data = [dict(zip(keys,row)) for row in data_iter]\n",
    "    conn.execute(insert(pd_table.table).on_conflict_do_nothing(), data)\n",
    "\n",
    "# Writes the dataframes to PostgreSQL tables\n",
    "tap_output.to_sql('tap_response_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "baseline_output.to_sql('tap_baseline_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "combined_Tstats_normalize_2.reset_index().to_sql('tstat_gene_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "combined_Tstats_normalize_allele_2.reset_index().to_sql('tstat_allele_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "combined_Tstats_normalized_melted.to_sql('gene_profile_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "combined_Tstats_normalized_melted_allele.to_sql('allele_profile_data', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "combined_MSD.to_sql('gene_MSD', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n",
    "allele_combined_MSD.to_sql('allele_MSD', engine, if_exists='append', index=False, method=postgres_skip_on_duplicate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c616-2839-4572-af70-233af783302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # USE THIS CELL TO UPDATE ALL THE NEED TALBES (Also have baseline_output on the second line)\n",
    "\n",
    "# conn=sqlite3.connect('/Users/lavanya/Desktop/Lavanya_Test/data_updated2.db')\n",
    "\n",
    "# tap_output.to_sql('tap_response_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# baseline_output.to_sql('tap_baseline_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalize_2.reset_index().to_sql('tstat_gene_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalize_allele_2.reset_index().to_sql('tstat_allele_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalized_melted.to_sql('gene_profile_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_Tstats_normalized_melted_allele.to_sql('allele_profile_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# combined_MSD.to_sql('gene_MSD', conn, if_exists='append', index=False)\n",
    "\n",
    "# allele_combined_MSD.to_sql('allele_MSD', conn, if_exists='append', index=False)\n",
    "\n",
    "# # combined_Tstats_melted_sorted.to_sql('allele_phenotype_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# print(conn.total_changes)\n",
    "\n",
    "# conn.close()\n",
    "\n",
    "\n",
    "# # Want to test edge cases of pd.to_sql functionality#############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
